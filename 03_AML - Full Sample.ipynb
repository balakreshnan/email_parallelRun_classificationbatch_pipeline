{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b960e716",
   "metadata": {},
   "source": [
    "## Import Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c598c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.36.0 to work with mm-aml\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "import os, shutil\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData, PublishedPipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData, PipelineEndpoint\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
    "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b5bd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz3/code/Users/memasanz/email-classification/batch-inferencing-full\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "folder_name = 'batch-inferencing-full'\n",
    "script_folder = os.path.join(os.getcwd(), folder_name)\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df03371",
   "metadata": {},
   "source": [
    "## Connect to AML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d07da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get default datastore\n",
    "default_ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d70365",
   "metadata": {},
   "source": [
    "## Create Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecaf6e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email-cluster4\n",
      "InProgress....\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded.............................\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "compute_name =  \"email-cluster4\"\n",
    "print(compute_name)\n",
    "\n",
    "# checks to see if compute target already exists in workspace, else create it\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
    "except ComputeTargetException:\n",
    "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D13\",\n",
    "                                                   min_nodes=2, \n",
    "                                                   max_nodes=10)\n",
    "\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a92bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz3/code/Users/memasanz/email-classification/batch-inferencing-full/email_classification_inference.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/email_classification_inference.yml\n",
    "name: email_classification_inference\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e7c139b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Create an Environment for the experiment\n",
    "batch_env = Environment.from_conda_specification(\"email_classification_inference\", script_folder + \"/email_classification_inference.yml\")\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "print('Configuration ready.')\n",
    "\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment = batch_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d8bedb",
   "metadata": {},
   "source": [
    "# Define Output Datasets\n",
    "\n",
    "Below we define the configuration for datasets that will be passed between steps in our pipeline. Note, in all cases we specify the datastore that should hold the datasets and whether they should be registered following step completion or not. This can optionally be disabled by removing the register_on_complete() call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a5627b",
   "metadata": {},
   "source": [
    "# Define Pipeline Parameters\n",
    "\n",
    "PipelineParameter objects serve as variable inputs to an Azure ML pipeline and can be specified at runtime. Below we specify a pipeline parameter object model_name which will be used to reference the locally trained model that was uploaded and registered within the Azure ML workspace. Multiple pipeline parameters can be created and used. Included here are multiple sample pipeline parameters (get_data_param_*) to highlight how parameters can be passed into and consumed by various pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d96d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = PipelineParameter(name='model_name', default_value='email_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a5ffe",
   "metadata": {},
   "source": [
    "# Define Pipeline Steps\n",
    "\n",
    "The pipeline below consists of steps to gather and register data from a remote source, a scoring step where the registered model is used to make predictions on loaded, and a data publish step where scored data can be exported to a remote data source. All of the PythonScriptSteps have a corresponding *.py file which is referenced in the step arguments. Also, any PipelineParameters defined above can be passed to and consumed within these steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea89bfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz3/code/Users/memasanz/email-classification/batch-inferencing\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "folder_name = 'batch-inferencing'\n",
    "script_folder = os.path.join(os.getcwd(), folder_name)\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b6bbd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz3/code/Users/memasanz/email-classification/batch-inferencing/batch_inferencing_data_silly.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/batch_inferencing_data_silly.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from azureml.core import Model\n",
    "import joblib\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def init():\n",
    "    # Runs when the pipeline step is initialized\n",
    "    global model\n",
    "\n",
    "    # load the model\n",
    "    print('****loaded model**********')\n",
    "    model_path = Model.get_model_path('email_classifier')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "def run(mini_batch):\n",
    "    # This runs for each batch\n",
    "    print(f'run method start: {__file__}, run({mini_batch})')\n",
    "    resultList = []\n",
    "    all_predictions = pd.DataFrame()\n",
    "    \n",
    "    for idx, file_path in enumerate(mini_batch):\n",
    "        file_name, file_extension = os.path.splitext(os.path.basename(file_path))\n",
    "       \n",
    "        #print(file_path)\n",
    "        #data = pd.read_csv(file_path)\n",
    "        \n",
    "        text_file = open(file_path, \"r\")\n",
    "        data = text_file.read()\n",
    "        text_file.close()\n",
    "        result = model.predict([data])\n",
    "        print(data)\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(file_path), result[0]))\n",
    "    #return resultList\n",
    "        \n",
    "        #for _, row in result_df.iterrows():\n",
    "        #    result_list.append((row))\n",
    "\n",
    "\n",
    "    #Return all rows formatted as a Pandas dataframe\n",
    "    return pd.DataFrame(resultList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068b3a0d",
   "metadata": {},
   "source": [
    "You're going to use a pipeline to run the batch prediction script, generate predictions from the input data, and save the results as a text file in the output folder. To do this, you can use a **ParallelRunStep**, which enables the batch data to be processed in parallel and the results collated in a single output file named *parallel_run_step.txt*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4c05a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Register a dataset for the input data\n",
    "batch_data_set = Dataset.File.from_files(path=(default_ds, 'spam-data-inferencing/'), validate=False)\n",
    "try:\n",
    "    batch_data_set = batch_data_set.register(workspace=ws, \n",
    "                                             name='spam-batch-data-inference',\n",
    "                                             description='inference batch data',\n",
    "                                             create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "708d7a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz3/code/Users/memasanz/email-classification/batch-inferencing'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4674c2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz3/code/Users/memasanz/email-classification/batch-inferencing/organize_data_silly.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/organize_data_silly.py\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "# Parse input arguments\n",
    "parser = argparse.ArgumentParser(\"parallel run step results directory\")\n",
    "parser.add_argument(\"--processed_dataset_tabular\", dest='processed_dataset_tabular', required=True)\n",
    "parser.add_argument(\"--processed_dataset\", type=str, required=True)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "#Get output data from previous step - saved as parallel_run_step.txt\n",
    "pipeline_data_file = os.path.join(args.processed_dataset, 'parallel_run_step.txt')\n",
    "\n",
    "#Parse as dataframe and assign headers\n",
    "df_pipeline_data = pd.read_csv(pipeline_data_file, header=None, delimiter=\" \")\n",
    "\n",
    "print(df_pipeline_data.columns)\n",
    "#df_pipeline_data.columns = ['D', 'E', 'F', 'G', 'A', 'B', 'C', 'Year']\n",
    "\n",
    "#Note: additional DF formatting operations can be done here\n",
    "\n",
    "#Create output directories for CSV/Excel files\n",
    "os.makedirs(args.processed_dataset_tabular, exist_ok=True)\n",
    "os.makedirs(args.processed_dataset, exist_ok=True)\n",
    "\n",
    "#Save output files to blob storage\n",
    "df_pipeline_data.to_csv(os.path.join(args.processed_dataset_tabular, 'processed_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8757888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "\n",
    "#output_dir = OutputFileDatasetConfig(name='inferences')\n",
    "processed_dataset_tabular = OutputFileDatasetConfig(name='processed_data_tabular', destination=(default_ds, 'processed_data_tabular/{run-id}')).read_delimited_files().register_on_complete(name='processed_data_tabular')\n",
    "#processed_dataset_file = OutputFileDatasetConfig(name='processed_data_file', destination=(default_ds, 'processed_data_file/{run-id}')).register_on_complete(name='processed_data_file')\n",
    "processed_dataset_pipeline_data = PipelineData(name='processed_data', datastore=default_ds)\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory=script_folder,\n",
    "    entry_script=\"batch_inferencing_data_silly.py\",\n",
    "    mini_batch_size=\"50\",\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=batch_env,\n",
    "    compute_target=compute_target,\n",
    "    node_count=2)\n",
    "\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name='batch-score-diabetes',\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[batch_data_set.as_named_input('email_batch')],\n",
    "    output=processed_dataset_pipeline_data,\n",
    "    arguments=[],\n",
    "    allow_reuse=False\n",
    ")\n",
    "\n",
    "organize_results_step = PythonScriptStep(\n",
    "    name='organize_results_step',\n",
    "    script_name='organize_data_silly.py',\n",
    "    arguments =['--processed_dataset_tabular', processed_dataset_tabular,\n",
    "               '--processed_dataset', processed_dataset_pipeline_data],\n",
    "    inputs=[processed_dataset_pipeline_data],\n",
    "    outputs=[processed_dataset_tabular],\n",
    "    compute_target=compute_target,\n",
    "    source_directory=script_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=run_config\n",
    ")\n",
    "\n",
    "print('Steps defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ce05cbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batch-score-diabetes [2afd0d45][2a035303-c981-4bee-a48c-896c7eb4ab56], (This step will run and generate new outputs)\n",
      "Created step organize_results_step [a4881947][572be0bd-048b-45b4-9048-4020134636a5], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 46352854-990d-4395-8f7d-ca085a449dc1\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/46352854-990d-4395-8f7d-ca085a449dc1?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-aml-rg/workspaces/mm-aml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRunId: 46352854-990d-4395-8f7d-ca085a449dc1\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/46352854-990d-4395-8f7d-ca085a449dc1?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-aml-rg/workspaces/mm-aml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 9a301142-d56f-4cda-bec9-a739ac1f7594\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9a301142-d56f-4cda-bec9-a739ac1f7594?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-aml-rg/workspaces/mm-aml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( batch-score-diabetes ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d.txt\n",
      "========================================================================================================================\n",
      "2022-02-09T03:55:46Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=368032 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2022-02-09T03:55:46Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/mounts/workspaceblobstore -- stdout/stderr: \n",
      "2022-02-09T03:55:46Z The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2022-02-09T03:55:46Z Starting output-watcher...\n",
      "2022-02-09T03:55:46Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_e8d7932f60b5241e5c58f00d93ad098c\n",
      "Digest: sha256:fa5a0434411f61f9191973238a617eed31ab52b0f2e9fe77079b976dda7044fc\n",
      "Status: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_e8d7932f60b5241e5c58f00d93ad098c:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_e8d7932f60b5241e5c58f00d93ad098c:latest\n",
      "2022-02-09T03:55:50Z The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2022-02-09T03:55:50Z Check if container 9a301142-d56f-4cda-bec9-a739ac1f7594_DataSidecar already exist exited with 0, \n",
      "\n",
      "582885fe8a3fdc12f9be5d4ef2e5c45d1114efabd737b9d038fcf81477c1176d\n",
      "2022-02-09T03:55:51Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2022-02-09T03:55:51Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-ce7acf226b388984cf5a6b502c076bc9-257a74572f225275-01 -sshRequired=false] \n",
      "2022/02/09 03:55:51 Didn't get JobInfoJson from env, now read from file\n",
      "2022/02/09 03:55:51 Suceeded read JobInfoJson from file\n",
      "2022/02/09 03:55:51 Starting App Insight Logger for task:  containerSetup\n",
      "2022/02/09 03:55:51 Version: 3.0.01853.0004 Branch: .SourceBranch Commit: df26c27\n",
      "2022/02/09 03:55:51 Entered ContainerSetupTask - Preparing infiniband\n",
      "2022/02/09 03:55:51 Starting infiniband setup\n",
      "2022/02/09 03:55:51 Python Version found is Python 3.7.9\n",
      "\n",
      "2022/02/09 03:55:51 Returning Python Version as 3.7\n",
      "2022-02-09T03:55:51Z VMSize: standard_d13, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2022-02-09T03:55:51Z Not setting up Infiniband in Container\n",
      "2022/02/09 03:55:51 VMSize: standard_d13, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2022/02/09 03:55:51 VMSize: standard_d13, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2022/02/09 03:55:51 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2022/02/09 03:55:51 Not setting up Infiniband in Container\n",
      "2022/02/09 03:55:51 Not setting up Infiniband in Container\n",
      "2022/02/09 03:55:51 Python Version found is Python 3.7.9\n",
      "\n",
      "2022/02/09 03:55:51 Returning Python Version as 3.7\n",
      "2022/02/09 03:55:51 sshd inside container not required for job, skipping setup.\n",
      "2022/02/09 03:55:52 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      "2022/02/09 03:55:52 App Insight Client has already been closed\n",
      "2022/02/09 03:55:52 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2022-02-09T03:55:52Z Starting docker container succeeded.\n",
      "2022-02-09T03:55:52Z The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d.txt\n",
      "===============================================================================================================\n",
      "[2022-02-09T03:55:50.122546] Entering job preparation.\n",
      "[2022-02-09T03:55:51.241028] Starting job preparation.\n",
      "[2022-02-09T03:55:51.241093] Extracting the control code.\n",
      "[2022-02-09T03:55:51.241628] Starting extract_project.\n",
      "[2022-02-09T03:55:51.241705] Starting to extract zip file.\n",
      "[2022-02-09T03:55:51.284304] Finished extracting zip file.\n",
      "[2022-02-09T03:55:51.287889] Using urllib.request Python 3.0 or later\n",
      "[2022-02-09T03:55:51.287938] Start fetching snapshots.\n",
      "[2022-02-09T03:55:51.287978] Start fetching snapshot.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 59\n",
      "[2022-02-09T03:55:51.786436] Finished fetching snapshot.\n",
      "[2022-02-09T03:55:51.786480] Start fetching snapshot.\n",
      "[2022-02-09T03:55:59.814063] Finished fetching snapshot.\n",
      "[2022-02-09T03:55:59.814109] Finished fetching snapshots.\n",
      "[2022-02-09T03:55:59.814123] Finished extract_project.\n",
      "[2022-02-09T03:55:59.814211] Finished fetching and extracting the control code.\n",
      "[2022-02-09T03:55:59.823638] Start run_history_prep.\n",
      "[2022-02-09T03:55:59.833114] Job preparation is complete.\n",
      "[2022-02-09T03:55:59.833273] Entering Data Context Managers in Sidecar\n",
      "[2022-02-09T03:55:59.834219] Running Sidecar prep cmd...\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-core 1.21.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('azure-core<1.21')).\n",
      "[2022-02-09T03:56:00.132051] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594\n",
      "[2022-02-09T03:56:00.132865] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"]}\n",
      "[2022-02-09T03:56:00.309] Enter __enter__ of DatasetContextManager\n",
      "[2022-02-09T03:56:00.310] SDK version: azureml-core==1.37.0.post1 azureml-dataprep==2.25.2. Session id: a8856f1b-d79f-4a55-b9ef-796d3eb18106. Run id: 9a301142-d56f-4cda-bec9-a739ac1f7594.\n",
      "[2022-02-09T03:56:00.310] Processing 'email_batch'.\n",
      "[2022-02-09T03:56:00.310] Mode: 'mount'.\n",
      "[2022-02-09T03:56:00.310] Path on compute is specified: 'False'.\n",
      "[2022-02-09T03:56:02.574] Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'spam-data-inferencing/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"86501b6f-875b-4ba7-9fc0-2f4b766a9390\",\n",
      "    \"name\": \"spam-batch-data-inference\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"inference batch data\",\n",
      "    \"workspace\": \"Workspace.create(name='mm-aml', subscription_id='5da07161-3770-4a4b-aa43-418cbbb627cf', resource_group='mm-aml-rg')\"\n",
      "  }\n",
      "}\n",
      "[2022-02-09T03:56:06.286] Mounting email_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/email_batch_86501b6f-875b-4ba7-9fc0-2f4b766a9390 as folder.\n",
      "[2022-02-09T03:56:06.313] Mounting email_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/email_batch_86501b6f-875b-4ba7-9fc0-2f4b766a9390.\n",
      "[2022-02-09T03:56:07.314] Mounted email_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/email_batch_86501b6f-875b-4ba7-9fc0-2f4b766a9390.\n",
      "[2022-02-09T03:56:07.416] Exit __enter__ of DatasetContextManager\n",
      "uri entered in sidecar: None\n",
      "Set Dataset email_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/email_batch_86501b6f-875b-4ba7-9fc0-2f4b766a9390\n",
      "Sidecar adding paths_to_bind: ['/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/tmpf40ah7tv:/tmp/8224756e-6203-4384-838a-ded6bc6b7977/8057d198-48cd-4d3b-9e67-f1295230eeb5']\n",
      "Acquired lockfile /tmp/9a301142-d56f-4cda-bec9-a739ac1f7594-datastore.lock to downloading input data references\n",
      "[2022-02-09T03:56:07.427555] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2022-02-09T03:56:07.672474] Ran Sidecar prep cmd.\n",
      "[2022-02-09T03:56:07.672583] Running Context Managers in Sidecar complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d.txt\n",
      "===============================================================================================================\n",
      "[2022-02-09T03:55:54.089657] Entering job preparation.\n",
      "[2022-02-09T03:55:54.679585] Starting job preparation.\n",
      "[2022-02-09T03:55:54.679622] Extracting the control code.\n",
      "[2022-02-09T03:55:54.679937] Starting extract_project.\n",
      "[2022-02-09T03:55:54.679984] Starting to extract zip file.\n",
      "[2022-02-09T03:55:54.706426] Finished extracting zip file.\n",
      "[2022-02-09T03:55:54.710315] Using urllib.request Python 3.0 or later\n",
      "[2022-02-09T03:55:54.710379] Start fetching snapshots.\n",
      "[2022-02-09T03:55:54.710413] Start fetching snapshot.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 59\n",
      "[2022-02-09T03:55:55.245082] Finished fetching snapshot.\n",
      "[2022-02-09T03:55:55.245128] Start fetching snapshot.\n",
      "[2022-02-09T03:56:02.819900] Finished fetching snapshot.\n",
      "[2022-02-09T03:56:02.819947] Finished fetching snapshots.\n",
      "[2022-02-09T03:56:02.819956] Finished extract_project.\n",
      "[2022-02-09T03:56:02.820037] Finished fetching and extracting the control code.\n",
      "[2022-02-09T03:56:02.828392] Start run_history_prep.\n",
      "[2022-02-09T03:56:02.836825] Job preparation is complete.\n",
      "[2022-02-09T03:56:02.837004] Entering Data Context Managers in Sidecar\n",
      "[2022-02-09T03:56:02.837979] Running Sidecar prep cmd...\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-core 1.21.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('azure-core<1.21')).\n",
      "[2022-02-09T03:56:03.199907] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594\n",
      "[2022-02-09T03:56:03.200809] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"]}\n",
      "[2022-02-09T03:56:03.425] Enter __enter__ of DatasetContextManager\n",
      "[2022-02-09T03:56:03.426] SDK version: azureml-core==1.37.0.post1 azureml-dataprep==2.25.2. Session id: 3f0ba744-7d09-449a-b4dd-c50381081612. Run id: 9a301142-d56f-4cda-bec9-a739ac1f7594.\n",
      "[2022-02-09T03:56:03.427] Processing 'email_batch'.\n",
      "[2022-02-09T03:56:03.427] Mode: 'mount'.\n",
      "[2022-02-09T03:56:03.427] Path on compute is specified: 'False'.\n",
      "[2022-02-09T03:56:05.725] Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'spam-data-inferencing/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"86501b6f-875b-4ba7-9fc0-2f4b766a9390\",\n",
      "    \"name\": \"spam-batch-data-inference\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"inference batch data\",\n",
      "    \"workspace\": \"Workspace.create(name='mm-aml', subscription_id='5da07161-3770-4a4b-aa43-418cbbb627cf', resource_group='mm-aml-rg')\"\n",
      "  }\n",
      "}\n",
      "[2022-02-09T03:56:10.776] Mounting email_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/email_batch_86501b6f-875b-4ba7-9fc0-2f4b766a9390 as folder.\n",
      "[2022-02-09T03:56:10.813] Mounting email_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/email_batch_86501b6f-875b-4ba7-9fc0-2f4b766a9390.\n",
      "[2022-02-09T03:56:11.815] Mounted email_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/email_batch_86501b6f-875b-4ba7-9fc0-2f4b766a9390.\n",
      "[2022-02-09T03:56:11.915] Exit __enter__ of DatasetContextManager\n",
      "uri entered in sidecar: None\n",
      "Set Dataset email_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/email_batch_86501b6f-875b-4ba7-9fc0-2f4b766a9390\n",
      "Sidecar adding paths_to_bind: ['/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/tmpjthb5mio:/tmp/8224756e-6203-4384-838a-ded6bc6b7977/8057d198-48cd-4d3b-9e67-f1295230eeb5']\n",
      "Acquired lockfile /tmp/9a301142-d56f-4cda-bec9-a739ac1f7594-datastore.lock to downloading input data references\n",
      "[2022-02-09T03:56:11.930338] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2022-02-09T03:56:12.589097] Ran Sidecar prep cmd.\n",
      "[2022-02-09T03:56:12.589240] Running Context Managers in Sidecar complete.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2022/02/09 03:56:17 Didn't get JobInfoJson from env, now read from file\n",
      "2022/02/09 03:56:17 Suceeded read JobInfoJson from file\n",
      "2022/02/09 03:56:17 Starting App Insight Logger for task:  runTaskLet\n",
      "2022/02/09 03:56:17 Version: 3.0.01853.0004 Branch: .SourceBranch Commit: df26c27\n",
      "2022/02/09 03:56:17 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2022/02/09 03:56:17 Send process info logs to master server succeeded\n",
      "2022/02/09 03:56:17 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2022/02/09 03:56:17 Send process info logs to master server succeeded\n",
      "[2022-02-09T03:56:17.350130] Entering context manager injector.\n",
      "[2022-02-09T03:56:17.909006] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.36.0', '--scoring_module_name', 'batch_inferencing_data_silly.py', '--mini_batch_size', '50', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/mounts/workspaceblobstore/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/processed_data', '--input_fds_0', 'email_batch'])\n",
      "Script type = None\n",
      "[2022-02-09T03:56:17.913373] Entering Run History Context Manager.\n",
      "[2022-02-09T03:56:18.676711] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594\n",
      "[2022-02-09T03:56:18.677063] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.36.0', '--scoring_module_name', 'batch_inferencing_data_silly.py', '--mini_batch_size', '50', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/mounts/workspaceblobstore/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/processed_data', '--input_fds_0', 'email_batch']\n",
      "[2022-02-09T03:56:18.677097] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.36.0', '--scoring_module_name', 'batch_inferencing_data_silly.py', '--mini_batch_size', '50', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/mounts/workspaceblobstore/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/processed_data', '--input_fds_0', 'email_batch']\n",
      "\n",
      "2022/02/09 03:56:22 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "\n",
      "[2022-02-09T03:56:54.950455] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "3 items cleaning up...\n",
      "Cleanup took 0.1879897117614746 seconds\n",
      "[2022-02-09T03:56:55.268054] Finished context manager injector.\n",
      "2022/02/09 03:56:56 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2022/02/09 03:56:56 Send process info logs to master server succeeded\n",
      "2022/02/09 03:56:56 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 2\n",
      "FilteredData: 0.\n",
      "2022/02/09 03:56:56 Process Exiting with Code:  0\n",
      "2022/02/09 03:56:56 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d.txt\n",
      "===============================================================================================================\n",
      "[2022-02-09T03:56:57.640595] Entering job release\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-core 1.21.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('azure-core<1.21')).\n",
      "[2022-02-09T03:56:58.353995] Starting job release\n",
      "[2022-02-09T03:56:58.354546] Logging experiment finalizing status in history service.[2022-02-09T03:56:58.354913] job release stage : upload_datastore starting...\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 270\n",
      "[2022-02-09T03:56:58.355402] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2022-02-09T03:56:58.355982] job release stage : execute_job_release starting...\n",
      "[2022-02-09T03:56:58.356243] job release stage : copy_batchai_cached_logs starting...\n",
      "\n",
      "[2022-02-09T03:56:58.370259] job release stage : copy_batchai_cached_logs completed...\n",
      "[2022-02-09T03:56:58.374159] Entering context manager injector.\n",
      "[2022-02-09T03:56:58.400025] job release stage : upload_datastore completed...\n",
      "[2022-02-09T03:56:58.451124] job release stage : send_run_telemetry starting...\n",
      "[2022-02-09T03:56:58.506129] get vm size and vm region successfully.\n",
      "[2022-02-09T03:56:58.523558] get compute meta data successfully.\n",
      "[2022-02-09T03:56:58.652014] job release stage : execute_job_release completed...\n",
      "[2022-02-09T03:56:58.729239] post artifact meta request successfully.\n",
      "[2022-02-09T03:56:58.794607] upload compute record artifact successfully.\n",
      "[2022-02-09T03:56:58.794730] job release stage : send_run_telemetry completed...\n",
      "[2022-02-09T03:56:58.795306] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2022-02-09T03:56:58.795463] Running Sidecar release cmd...\n",
      "[2022-02-09T03:56:58.807647] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594\n",
      "[2022-02-09T03:56:58.829] Enter __exit__ of DatasetContextManager\n",
      "[2022-02-09T03:56:58.829] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/email_batch_86501b6f-875b-4ba7-9fc0-2f4b766a9390.\n",
      "[2022-02-09T03:56:59.846] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/email_batch_86501b6f-875b-4ba7-9fc0-2f4b766a9390.\n",
      "[2022-02-09T03:56:59.846] Exit __exit__ of DatasetContextManager\n",
      "[2022-02-09T03:56:59.846562] Removing absolute paths from host...\n",
      "[2022-02-09T03:56:59.846967] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2022-02-09T03:57:00.042755] Ran Sidecar release cmd.\n",
      "[2022-02-09T03:57:00.042901] Job release is complete\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d.txt\n",
      "===============================================================================================================\n",
      "[2022-02-09T03:56:58.339072] Entering job release\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-core 1.21.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('azure-core<1.21')).\n",
      "[2022-02-09T03:56:59.195267] job release stage : copy_batchai_cached_logs starting...\n",
      "[2022-02-09T03:56:59.195313] job release stage : copy_batchai_cached_logs completed...\n",
      "[2022-02-09T03:56:59.195361] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2022-02-09T03:56:59.195918] Running Sidecar release cmd...\n",
      "[2022-02-09T03:56:59.206137] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594\n",
      "[2022-02-09T03:56:59.220] Enter __exit__ of DatasetContextManager\n",
      "[2022-02-09T03:56:59.220] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/email_batch_86501b6f-875b-4ba7-9fc0-2f4b766a9390.\n",
      "[2022-02-09T03:57:00.229] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mm-aml/azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/wd/email_batch_86501b6f-875b-4ba7-9fc0-2f4b766a9390.\n",
      "[2022-02-09T03:57:00.229] Exit __exit__ of DatasetContextManager\n",
      "[2022-02-09T03:57:00.229625] Removing absolute paths from host...\n",
      "[2022-02-09T03:57:00.239270] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2022-02-09T03:57:00.657757] Ran Sidecar release cmd.\n",
      "\n",
      "StepRun(batch-score-diabetes) Execution Summary\n",
      "================================================\n",
      "StepRun( batch-score-diabetes ) Status: Finished\n",
      "{'runId': '9a301142-d56f-4cda-bec9-a739ac1f7594', 'target': 'email-cluster4', 'status': 'Completed', 'startTimeUtc': '2022-02-09T03:55:41.393063Z', 'endTimeUtc': '2022-02-09T03:57:20.783641Z', 'services': {}, 'properties': {'ContentSnapshotId': '229f8497-8464-4a32-a669-58744e514fa2', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '2a035303-c981-4bee-a48c-896c7eb4ab56', 'azureml.moduleName': 'batch-score-diabetes', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '2afd0d45', 'azureml.pipelinerunid': '46352854-990d-4395-8f7d-ca085a449dc1', 'azureml.pipeline': '46352854-990d-4395-8f7d-ca085a449dc1', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': '86501b6f-875b-4ba7-9fc0-2f4b766a9390'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'email_batch', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.36.0', '--scoring_module_name', 'batch_inferencing_data_silly.py', '--mini_batch_size', '50', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZUREML_DATAREFERENCE_processed_data', '--input_fds_0', 'email_batch'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'email-cluster4', 'dataReferences': {'processed_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/processed_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'email_batch': {'dataLocation': {'dataset': {'id': '86501b6f-875b-4ba7-9fc0-2f4b766a9390', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'email_batch', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'email_classification_inference', 'version': 'Autosave_2022-01-13T22:29:01Z_b98d5e46', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211029.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/azureml-logs/55_azureml-execution-tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d.txt?sv=2019-07-07&sr=b&sig=loGBqjH9Gs9MPYHIDIQTm6R5ZYeA1TZa7yVB9edx7BY%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/azureml-logs/55_azureml-execution-tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d.txt?sv=2019-07-07&sr=b&sig=WjiNDFslB9V3iYZ53E8LQlOHXl2SBZ36817jwAC0Tk0%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'azureml-logs/65_job_prep-tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/azureml-logs/65_job_prep-tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d.txt?sv=2019-07-07&sr=b&sig=awPW%2Fd2305LpHUjVEcPQmHrxzAqAN5Zu60yXGBTwIhY%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'azureml-logs/65_job_prep-tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/azureml-logs/65_job_prep-tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d.txt?sv=2019-07-07&sr=b&sig=Sk%2B98GNwNDzaicziDnonWDmtgbDiSQM7VPdUsaZGd68%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=3O2dMWHyRluJcrK1oUHd77twVU30RzQQCCxEbVzBTc0%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'azureml-logs/75_job_post-tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/azureml-logs/75_job_post-tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d.txt?sv=2019-07-07&sr=b&sig=Zp3MjHdGICpmADnNj1sYrrZsOLvNnjehEyd%2BYH4X64c%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'azureml-logs/75_job_post-tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/azureml-logs/75_job_post-tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d.txt?sv=2019-07-07&sr=b&sig=h1qfFi6f%2FEzft2H8TYuGGJ0wOkjXroZEVyRk9wcxWOI%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'azureml-logs/process_info.json': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=Tph1xn1xohTSPtjKnYLJ7bfTYj1t8QgTbaVEc6FaXkM%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'azureml-logs/process_status.json': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=01BW0S%2BXX8DSqsyWsMjLQUtYDka1AlmmsXFeEQuJGUg%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/100_azureml.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/100_azureml.log?sv=2019-07-07&sr=b&sig=QjBC79QSWH8BTbzRx4ejeyyAFPzUcB91eDGobm5M7I0%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/113_azureml.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/113_azureml.log?sv=2019-07-07&sr=b&sig=GNfAlogzT5AMbn24QxehjzsqrWkCmBCz6R6oNYXKYn8%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=RF7XpPcJNgsCbuyiFDqE1Z%2BHHkpJA76zIjTeqmUOcZw%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=4bfElguYloTpZ0aGMUKs87KgJw%2FQC%2Fa6FWHYeOBzx7M%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=TkBUUEbbyRkjkdTmC%2FGBmQFyK%2FNIxLgSqyhkJVxZBQY%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=I2z5Z3LFWCgPf9LL68mgfLpYoWzboamxSmd7qOXFb4Q%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=3%2BGXa6FvfQIjWGun%2BjvcZuiEq18f4jJoZCuk8%2BWIc0o%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d/all.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/sidecar/tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d/all.log?sv=2019-07-07&sr=b&sig=Puvg1Q%2FUIJwJve673PrPZu%2FJId8w95aFcA5em6dwVGA%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d/task.enter_contexts.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/sidecar/tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=CxZ3QEAwuZNiW%2BGtiN1iiM0g7j%2BgDsec3YrEG5%2BP8Cg%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d/task.exit_contexts.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/sidecar/tvmps_da4590140e005d016588fac651f6e849438c236ca6a0b0ebc29b1650980d8ec3_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=Z0GbSIl2tZWph1avEJ4w4Mc%2BKtxQdtldFmvV4lR3W8A%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d/all.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/sidecar/tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d/all.log?sv=2019-07-07&sr=b&sig=FJyf7AlV3tQS2F1N87fCNnqVuoqwo6pG7a0D0R1Gwr0%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d/task.enter_contexts.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/sidecar/tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=demf7IKqJQ5J0I%2BA%2FzNFXBU2t%2FaQLCx3Xzh8kShRFIg%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d/task.exit_contexts.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/sidecar/tvmps_e5f4889012407b04b6960f655a653511d548653b406509361f03a8736e6338b9_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=pAT8bo0rIQczDNqhuczZ%2F2LyXfWFFhBwD%2FoR3BXn48g%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=b0e0p3mbXVG57y7K9dSV8HMJU8GbbHkM%2BIuI3ZlJ8Go%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.9a301142-d56f-4cda-bec9-a739ac1f7594/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=ZFvt7F4hBLDa7MY2P5zfyILL7j2Jcx4W5hPMcoM%2FRaw%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A10Z&se=2022-02-09T11%3A57%3A10Z&sp=r'}, 'submittedBy': 'Megan Masanz'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: a40eab6b-b6e9-4c00-b478-7338146a9581\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/a40eab6b-b6e9-4c00-b478-7338146a9581?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-aml-rg/workspaces/mm-aml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( organize_results_step ) Status: Running\n",
      "\n",
      "StepRun(organize_results_step) Execution Summary\n",
      "=================================================\n",
      "StepRun( organize_results_step ) Status: Finished\n",
      "{'runId': 'a40eab6b-b6e9-4c00-b478-7338146a9581', 'target': 'email-cluster4', 'status': 'Completed', 'startTimeUtc': '2022-02-09T03:57:30.879317Z', 'endTimeUtc': '2022-02-09T03:58:12.906417Z', 'services': {}, 'properties': {'ContentSnapshotId': '229f8497-8464-4a32-a669-58744e514fa2', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '572be0bd-048b-45b4-9048-4020134636a5', 'azureml.moduleName': 'organize_results_step', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'a4881947', 'azureml.pipelinerunid': '46352854-990d-4395-8f7d-ca085a449dc1', 'azureml.pipeline': '46352854-990d-4395-8f7d-ca085a449dc1', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [{'identifier': {'savedId': 'cd62dbb4-0afa-4c74-a768-b90669cf561f', 'registeredId': '40263786-587a-4587-a1ae-b7293c427ee1', 'registeredVersion': '2'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'processed_data_tabular'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'processed_data_tabular/a40eab6b-b6e9-4c00-b478-7338146a9581')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"cd62dbb4-0afa-4c74-a768-b90669cf561f\",\n",
      "    \"name\": \"processed_data_tabular\",\n",
      "    \"version\": 2,\n",
      "    \"workspace\": \"Workspace.create(name='mm-aml', subscription_id='5da07161-3770-4a4b-aa43-418cbbb627cf', resource_group='mm-aml-rg')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'organize_data_silly.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--processed_dataset_tabular', 'DatasetOutputConfig:processed_data_tabular', '--processed_dataset', '$AZUREML_DATAREFERENCE_processed_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'email-cluster4', 'dataReferences': {'processed_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/9a301142-d56f-4cda-bec9-a739ac1f7594/processed_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {'processed_data_tabular': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'processed_data_tabular/{run-id}'}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': 'processed_data_tabular', 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '46352854-990d-4395-8f7d-ca085a449dc1', 'azureml.pipelineRun.moduleNodeId': 'a4881947', 'azureml.pipelineRun.outputPortName': 'processed_data_tabular'}, 'datasetRegistrationOptions': {'additionalTransformation': '{\\n  \"blocks\": [\\n    {\\n      \"id\": \"3351b78e-1b64-40db-b391-ba2a9d20be46\",\\n      \"type\": \"Microsoft.DPrep.ParseDelimitedBlock\",\\n      \"arguments\": {\\n        \"columnHeadersMode\": 3,\\n        \"fileEncoding\": 0,\\n        \"handleQuotedLineBreaks\": false,\\n        \"preview\": false,\\n        \"separator\": \",\",\\n        \"skipRows\": 0,\\n        \"skipRowsMode\": 0\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    },\\n    {\\n      \"id\": \"341dcf07-bfdb-4df2-a94e-d990ae6f641c\",\\n      \"type\": \"Microsoft.DPrep.DropColumnsBlock\",\\n      \"arguments\": {\\n        \"columns\": {\\n          \"type\": 0,\\n          \"details\": {\\n            \"selectedColumns\": [\\n              \"Path\"\\n            ]\\n          }\\n        }\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    }\\n  ],\\n  \"inspectors\": [],\\n  \"meta\": {\\n    \"steps_added\": \"2\"\\n  }\\n}'}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'email_classification_inference', 'version': 'Autosave_2022-01-13T22:29:01Z_b98d5e46', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211029.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.a40eab6b-b6e9-4c00-b478-7338146a9581/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=n%2BNmSOyW6a7Q5RUg30hLHgrfaCpnqm%2Ff9JzXvrZQAMs%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A29Z&se=2022-02-09T11%3A57%3A29Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.a40eab6b-b6e9-4c00-b478-7338146a9581/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=WNFj742h%2F3yXAHUnbEERa0Ch8%2FDiUcAI29ile7Ww8dw%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A29Z&se=2022-02-09T11%3A57%3A29Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.a40eab6b-b6e9-4c00-b478-7338146a9581/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=aO4eKKMna9ruq1yXQT9pd5vyeryh2I9mWXIgX7MVwgY%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A47%3A29Z&se=2022-02-09T11%3A57%3A29Z&sp=r'}, 'submittedBy': 'Megan Masanz'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '46352854-990d-4395-8f7d-ca085a449dc1', 'status': 'Completed', 'startTimeUtc': '2022-02-09T03:55:28.209294Z', 'endTimeUtc': '2022-02-09T03:58:15.921139Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.46352854-990d-4395-8f7d-ca085a449dc1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=%2FjMabgox8DWx0zogDM0rVxWLm4QaOnBvxpxkGxx5NsA%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A46%3A05Z&se=2022-02-09T11%3A56%3A05Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.46352854-990d-4395-8f7d-ca085a449dc1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=gp7NdLEUC4Wise1ABpu2GsxeexqQfc8YMtZkkbPNSuM%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A46%3A05Z&se=2022-02-09T11%3A56%3A05Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.46352854-990d-4395-8f7d-ca085a449dc1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=Mptwd%2B%2B%2F633Rc66otd4v6PH5shO9uPcF8%2BtogcOea%2Fg%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T01%3A10%3A27Z&ske=2022-02-10T09%3A20%3A27Z&sks=b&skv=2019-07-07&st=2022-02-09T03%3A46%3A05Z&se=2022-02-09T11%3A56%3A05Z&sp=r'}, 'submittedBy': 'Megan Masanz'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step, organize_results_step])\n",
    "pipeline_run = Experiment(ws, '03-email-classifcation-batch-inference_full').submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da212398",
   "metadata": {},
   "source": [
    "## Publish the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17da7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# published_pipeline = pipeline.publish(name = 'Email Batch Prediction Pipeline Silly',\n",
    "#                                      description = 'Pipeline that generates batch predictions using a registered trained model.',\n",
    "#                                      continue_on_step_failure = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e640a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\n",
    "# pipeline_id = '2c8fc5ae-1508-4bf9-9dda-24c21fb2e8aa'\n",
    "# experiment_name = 'scheduled_silly_email'\n",
    "# recurrence = ScheduleRecurrence(frequency=\"Minute\", interval=5)\n",
    "# recurring_schedule = Schedule.create(ws, name=\"MyRecurringSchedule\", \n",
    "#                             description=\"Based on time\",\n",
    "#                             pipeline_id=pipeline_id, \n",
    "#                             experiment_name=experiment_name, \n",
    "#                             recurrence=recurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4073cf4",
   "metadata": {},
   "source": [
    "## Get published pipeline Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b584f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments = Experiment.list(ws)\n",
    "# # for experiment in experiments:\n",
    "# #     print(experiment.name)\n",
    "\n",
    "# published_pipelines = PublishedPipeline.list(ws)\n",
    "# for published_pipeline in  published_pipelines:\n",
    "#     print(f\"{published_pipeline.name},'{published_pipeline.id}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss = Schedule.list(ws)\n",
    "# for s in ss:\n",
    "#     print(s)\n",
    "#     print('****************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa5e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stop_by_schedule_id(ws, schedule_id):\n",
    "#     s = next(s for s in Schedule.list(ws) if s.id == schedule_id)\n",
    "#     s.disable()\n",
    "#     return s\n",
    "\n",
    "# #stop_by_schedule_id(ws, '60166fcd-5276-4557-9a5b-c5a0ce3ec84e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cabf2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = PublishedPipeline.get(ws, id = '898c1939-7278-4ce8-976f-106b71bbb678')\n",
    "# pipeline.disable()\n",
    "\n",
    "# # for published_pipeline in  published_pipelines:\n",
    "# #     pipeline = PublishedPipeline.get(ws, id = published_pipeline.id)\n",
    "# #     pipeline.disable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6fdf4b",
   "metadata": {},
   "source": [
    "## Set Schedule for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165ab516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_id = published_pipeline.Id\n",
    "# experiment_name = 'silly_scheduled_email'\n",
    "# recurrence = ScheduleRecurrence(frequency=\"Minute\", interval=5)\n",
    "# recurring_schedule = Schedule.create(ws, name=\"MyRecurringSchedule\", \n",
    "#                             description=\"Based on time\",\n",
    "#                             pipeline_id=pipeline_id, \n",
    "#                             experiment_name=experiment_name, \n",
    "#                             recurrence=recurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import shutil\n",
    "\n",
    "# # Remove the local results folder if left over from a previous run\n",
    "# # shutil.rmtree('diabetes-results', ignore_errors=True)\n",
    "\n",
    "# # Get the run for the first step and download its output\n",
    "# prediction_run = next(pipeline_run.get_children())\n",
    "# prediction_output = prediction_run.get_output_data('inferences')\n",
    "# prediction_output.download(local_path='diabetes-results')\n",
    "\n",
    "# # Traverse the folder hierarchy and find the results file\n",
    "# for root, dirs, files in os.walk('diabetes-results'):\n",
    "#     for file in files:\n",
    "#         if file.endswith('parallel_run_step.txt'):\n",
    "#             result_file = os.path.join(root,file)\n",
    "\n",
    "# # cleanup output format\n",
    "# df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "# df.columns = [\"File\", \"Prediction\"]\n",
    "\n",
    "# # Display the first 20 results\n",
    "# df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
