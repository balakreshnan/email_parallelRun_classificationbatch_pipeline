{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This sample notebook shows creating an experiment to train a model for classification, the model will be registered and leveraged for inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMS Spam Collection Dataset\n",
    "Source: https://www.kaggle.com/uciml/sms-spam-collection-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.37.0 to work with mm-aml-dev-ops\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./datasets/spamformodel.csv')\n",
    "inferecing_data = pd.read_csv('./datasets/spamformodel.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2591</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                    text\n",
       "count    3000                    3000\n",
       "unique      2                    2851\n",
       "top       ham  Sorry, I'll call later\n",
       "freq     2591                      19"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created!\n"
     ]
    }
   ],
   "source": [
    "# Create a folder\n",
    "batch_folder = './batch-data'\n",
    "os.makedirs(batch_folder, exist_ok=True)\n",
    "print(\"Folder created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./datasets/spamformodel.csv\n",
      "Uploaded ./datasets/spamformodel.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0     ham  Go until jurong point, crazy.. Available only ...\n",
       "1     ham                      Ok lar... Joking wif u oni...\n",
       "2    spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3     ham  U dun say so early hor... U c already then say...\n",
       "4     ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5    spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6     ham  Even my brother is not like to speak with me. ...\n",
       "7     ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8    spam  WINNER!! As a valued network customer you have...\n",
       "9    spam  Had your mobile 11 months or more? U R entitle...\n",
       "10    ham  I'm gonna be home soon and i don't want to tal...\n",
       "11   spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12   spam  URGENT! You have won a 1 week FREE membership ...\n",
       "13    ham  I've been searching for the right words to tha...\n",
       "14    ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15   spam  XXXMobileMovieClub: To use your credit, click ...\n",
       "16    ham                         Oh k...i'm watching here:)\n",
       "17    ham  Eh u remember how 2 spell his name... Yes i di...\n",
       "18    ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...\n",
       "19   spam  England v Macedonia - dont miss the goals/team..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "default_ds.upload_files(files=['./datasets/spamformodel.csv'], # Upload the diabetes csv files in /data\n",
    "                        target_path= 'spam-data', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "    \n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'spam-data/spamformodel.csv'))\n",
    "\n",
    "try:\n",
    "    tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                        name='email_dataset',\n",
    "                                        description='email spam or ham data',\n",
    "                                        tags = {'format':'CSV'},\n",
    "                                        create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "# Display the first 20 rows as a Pandas dataframe\n",
    "tab_data_set.take(20).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "Y = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "transformed_vector = count_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 6245)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2550)\t1\n",
      "  (0, 5784)\t1\n",
      "  (0, 3124)\t1\n",
      "  (0, 4249)\t1\n",
      "  (0, 1641)\t1\n",
      "  (0, 894)\t1\n",
      "  (0, 3977)\t1\n",
      "  (0, 2928)\t1\n",
      "  (0, 1224)\t1\n",
      "  (0, 2604)\t1\n",
      "  (0, 6120)\t1\n",
      "  (0, 3214)\t1\n",
      "  (0, 1222)\t1\n",
      "  (0, 1431)\t1\n",
      "  (0, 5501)\t1\n",
      "  (0, 2581)\t1\n",
      "  (0, 727)\t1\n",
      "  (0, 5955)\t1\n"
     ]
    }
   ],
   "source": [
    "#word frequecy\n",
    "print(transformed_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_transformer = TfidfTransformer() \n",
    "tfidf_vector = tfid_transformer.fit_transform(transformed_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6120)\t0.2194752986462319\n",
      "  (0, 5955)\t0.19473901783061617\n",
      "  (0, 5784)\t0.22793693965845888\n",
      "  (0, 5501)\t0.15784322212997065\n",
      "  (0, 4249)\t0.2506070193198575\n",
      "  (0, 3977)\t0.16363891047125267\n",
      "  (0, 3214)\t0.28050545509161845\n",
      "  (0, 3124)\t0.31525135382042524\n",
      "  (0, 2928)\t0.11038091843908045\n",
      "  (0, 2604)\t0.18889359811399475\n",
      "  (0, 2581)\t0.15874972350310806\n",
      "  (0, 2550)\t0.1538778038097993\n",
      "  (0, 1641)\t0.26268283838726564\n",
      "  (0, 1431)\t0.2735917909803556\n",
      "  (0, 1224)\t0.2735917909803556\n",
      "  (0, 1222)\t0.2998760486969354\n",
      "  (0, 894)\t0.2542211973750386\n",
      "  (0, 727)\t0.31525135382042524\n"
     ]
    }
   ],
   "source": [
    "#tfidf score per document\n",
    "print(tfidf_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_vector, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_classification(y_test, y_pred):\n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True) #how many predictions correct %\n",
    "    num_acc = accuracy_score(y_test, y_pred, normalize = False)\n",
    "    prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print('aacuracy count:', num_acc)\n",
    "    print('accuracy score:', acc)\n",
    "    print('precision:', prec)\n",
    "    print('recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB().fit(x_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aacuracy count: 538\n",
      "accuracy score: 0.8966666666666666\n",
      "precision: 0.9257976381289265\n",
      "recall: 0.8966666666666666\n"
     ]
    }
   ],
   "source": [
    "summarize_classification(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz5/code/Users/memasanz/email_parallelRun_classificationbatch_pipeline/train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"train\")\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz5/code/Users/memasanz/email_parallelRun_classificationbatch_pipeline/train/classifier_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/classifier_training.py\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def summarize_classification(y_test, y_pred, run):\n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True) #how many predictions correct %\n",
    "    num_acc = accuracy_score(y_test, y_pred, normalize = False)\n",
    "    prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    run.log('acc count', num_acc)\n",
    "    run.log('Accuracy', acc)\n",
    "    run.log('prec', prec)\n",
    "    run.log('recall', recall)\n",
    "    \n",
    "    print('aacuracy count:', num_acc)\n",
    "    print('accuracy score:', acc)\n",
    "    print('precision:', prec)\n",
    "    print('recall:', recall)\n",
    "    \n",
    "\n",
    "\n",
    "def getRuntimeArgs():\n",
    "    # Get script arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "def model_train(ds_df, run):\n",
    "    \n",
    "    X = ds_df['text']\n",
    "    Y = ds_df['labels']\n",
    "    #sklearn pipeline\n",
    "    clf = Pipeline([\n",
    "                            ('count_vectorizer', CountVectorizer()),\n",
    "                            ('classifier', LogisticRegression(solver='lbfgs', max_iter=10000))\n",
    "                        ])\n",
    "    #output of convectorizer, feed to classifier\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "    print('type of x_test')\n",
    "    print(type(x_test))\n",
    "    model = clf.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    print('*************************')\n",
    "    print('model predictions:')\n",
    "    print(y_pred)\n",
    "    summarize_classification(y_test, y_pred, run)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = getRuntimeArgs()\n",
    "    \n",
    "    # Get the experiment run context\n",
    "    run = Run.get_context()\n",
    "    \n",
    "    dataset_dir = './dataset/'\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    ws = run.experiment.workspace\n",
    "    print(ws)\n",
    "    \n",
    "    \n",
    "    print(\"Loading Data...\")\n",
    "    data = run.input_datasets['training_data'].to_pandas_dataframe()\n",
    "    \n",
    "    \n",
    "    print(data.columns)\n",
    "    lr = model_train(data, run)\n",
    "    \n",
    "    \n",
    "    # Save the trained model\n",
    "    model_file = 'email_classifier.pkl'\n",
    "    joblib.dump(value=lr, filename=model_file)\n",
    "    run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
    "\n",
    "    # Complete the run\n",
    "    run.complete()\n",
    "\n",
    "\n",
    "    # Register the model\n",
    "    run.register_model(model_path='outputs/email_classifier.pkl', model_name='email_classifier',\n",
    "                       tags={'Training context':'spam or ham'})\n",
    "\n",
    "    #print('Model trained and registered.')\n",
    " \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mm-cluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "user = 'mm'\n",
    "compute_name = user + \"-cluster\"\n",
    "print(compute_name)\n",
    "\n",
    "# checks to see if compute target already exists in workspace, else create it\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
    "except ComputeTargetException:\n",
    "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D13\",\n",
    "                                                   min_nodes=0, \n",
    "                                                   max_nodes=1)\n",
    "\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz5/code/Users/memasanz/email_parallelRun_classificationbatch_pipeline/train/experiment_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/experiment_env.yml\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email classification defined.\n",
      "name: experiment_env\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "- scikit-learn\n",
      "- ipykernel\n",
      "- matplotlib\n",
      "- pandas\n",
      "- pip\n",
      "- pip:\n",
      "  - azureml-defaults\n",
      "  - pyarrow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(\"email classification\", script_folder + \"/experiment_env.yml\")\n",
    "\n",
    "# Let Azure ML manage dependencies\n",
    "experiment_env.python.user_managed_dependencies = False \n",
    "\n",
    "# Print the environment details\n",
    "print(experiment_env.name, 'defined.')\n",
    "print(experiment_env.python.conda_dependencies.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c73f54265604ae995ead8bd8e1a858c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/00_email_classification_model_1644386043_55e20ecf?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-aml-dev-ops-rg/workspaces/mm-aml-dev-ops&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"00_email_classification_model_1644386043_55e20ecf\", \"run_properties\": {\"run_id\": \"00_email_classification_model_1644386043_55e20ecf\", \"created_utc\": \"2022-02-09T05:54:04.249567Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"8291c21f-5c33-4c2a-9ad4-e16a35d625e3\", \"azureml.git.repository_uri\": \"https://github.com/memasanz/email_parallelRun_classificationbatch_pipeline.git\", \"mlflow.source.git.repoURL\": \"https://github.com/memasanz/email_parallelRun_classificationbatch_pipeline.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"8f48c46db768dc633209fa56d4f78551a54a6c03\", \"mlflow.source.git.commit\": \"8f48c46db768dc633209fa56d4f78551a54a6c03\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-02-09T05:54:25.650326Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=QPuU21ko9DCNHlAcHtRIIq1OAUlp6shV00j4YQPoS%2Fg%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T05%3A37%3A09Z&ske=2022-02-10T13%3A47%3A09Z&sks=b&skv=2019-07-07&st=2022-02-09T05%3A44%3A26Z&se=2022-02-09T13%3A54%3A26Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=hd7jYRz1Ufzq849ReS68jgw6WwM%2FCukPTE980%2FGB2Uc%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T05%3A37%3A09Z&ske=2022-02-10T13%3A47%3A09Z&sks=b&skv=2019-07-07&st=2022-02-09T05%3A44%3A26Z&se=2022-02-09T13%3A54%3A26Z&sp=r\", \"logs/azureml/22751_azureml.log\": \"https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/logs/azureml/22751_azureml.log?sv=2019-07-07&sr=b&sig=NhO4kxSpe3PX4lU6G8TQGPq35LhrPhvrFvs1umkzmwY%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T05%3A37%3A09Z&ske=2022-02-10T13%3A47%3A09Z&sks=b&skv=2019-07-07&st=2022-02-09T05%3A44%3A19Z&se=2022-02-09T13%3A54%3A19Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=WNdOjjYWPJWhv7oReZVXgLzOI%2BPgKAotO8n9RSRCZ%2BA%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T05%3A37%3A09Z&ske=2022-02-10T13%3A47%3A09Z&sks=b&skv=2019-07-07&st=2022-02-09T05%3A44%3A19Z&se=2022-02-09T13%3A54%3A19Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=ORinErNLDUZ699D%2B%2FD3oxx%2FvEJRvKEbWqT3m50kY0Nk%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T05%3A37%3A09Z&ske=2022-02-10T13%3A47%3A09Z&sks=b&skv=2019-07-07&st=2022-02-09T05%3A44%3A19Z&se=2022-02-09T13%3A54%3A19Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/22751_azureml.log\"]], \"run_duration\": \"0:00:21\", \"run_number\": \"1644386044\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"acc count\", \"run_id\": \"00_email_classification_model_1644386043_55e20ecf\", \"categories\": [0], \"series\": [{\"data\": [589]}]}, {\"name\": \"Accuracy\", \"run_id\": \"00_email_classification_model_1644386043_55e20ecf\", \"categories\": [0], \"series\": [{\"data\": [0.9816666666666667]}]}, {\"name\": \"prec\", \"run_id\": \"00_email_classification_model_1644386043_55e20ecf\", \"categories\": [0], \"series\": [{\"data\": [0.9815555555555556]}]}, {\"name\": \"recall\", \"run_id\": \"00_email_classification_model_1644386043_55e20ecf\", \"categories\": [0], \"series\": [{\"data\": [0.9816666666666667]}]}], \"run_logs\": \"2022-02-09 05:54:05,823|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\n2022-02-09 05:54:05,824|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: none\\n2022-02-09 05:54:05,824|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2022-02-09 05:54:05,824|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2022-02-09 05:54:06,406|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f008051e488> for run source azureml.scriptrun\\n2022-02-09 05:54:06,407|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-02-09 05:54:06,407|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-02-09 05:54:06,412|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2022-02-09 05:54:06,421|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2022-02-09 05:54:06,421|azureml.core.authentication|DEBUG|Time to expire 1814397.578168 seconds\\n2022-02-09 05:54:06,422|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2022-02-09 05:54:06,422|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:06,422|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:06,423|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:06,423|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:06,423|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:06,423|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:06,423|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:06,563|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-02-09 05:54:06,563|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-02-09 05:54:06,634|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-02-09 05:54:06,636|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '8291c21f-5c33-4c2a-9ad4-e16a35d625e3', 'azureml.git.repository_uri': 'https://github.com/memasanz/email_parallelRun_classificationbatch_pipeline.git', 'mlflow.source.git.repoURL': 'https://github.com/memasanz/email_parallelRun_classificationbatch_pipeline.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '8f48c46db768dc633209fa56d4f78551a54a6c03', 'mlflow.source.git.commit': '8f48c46db768dc633209fa56d4f78551a54a6c03', 'azureml.git.dirty': 'True'}\\n2022-02-09 05:54:06,636|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-02-09 05:54:06,636|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2022-02-09 05:54:06,636|azureml.WorkerPool|DEBUG|[START]\\n2022-02-09 05:54:06,637|azureml.SendRunKillSignal|DEBUG|[START]\\n2022-02-09 05:54:06,637|azureml.RunStatusContext|DEBUG|[START]\\n2022-02-09 05:54:06,637|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunContextManager.RunStatusContext|DEBUG|[START]\\n2022-02-09 05:54:06,637|azureml.MetricsClient|DEBUG|[START]\\n2022-02-09 05:54:06,637|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2022-02-09 05:54:06,637|azureml.ContentUploader|DEBUG|[START]\\n2022-02-09 05:54:06,638|azureml._history.utils.context_managers|DEBUG|starting file watcher\\n2022-02-09 05:54:06,639|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\n2022-02-09 05:54:06,639|azureml.TrackFolders|DEBUG|[START]\\n2022-02-09 05:54:06,639|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2022-02-09 05:54:06,639|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2022-02-09 05:54:06,639|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/00_email_classification_model_1644386043_55e20ecf\\n2022-02-09 05:54:06,639|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2022-02-09 05:54:06,639|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /tmp/azureml_runs/00_email_classification_model_1644386043_55e20ecf\\n2022-02-09 05:54:06,651|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-02-09 05:54:06,651|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-02-09 05:54:06,838|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-02-09 05:54:06,905|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/logs/azureml/22751_azureml.log path: /tmp/azureml_runs/00_email_classification_model_1644386043_55e20ecf/logs/azureml/22751_azureml.log\\n2022-02-09 05:54:06,906|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-02-09 05:54:06,907|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\n2022-02-09 05:54:06,907|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\n2022-02-09 05:54:08,093|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-02-09 05:54:08,093|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-02-09 05:54:08,094|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2022-02-09 05:54:08,094|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,094|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,095|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,095|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,095|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,095|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,095|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,133|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-02-09 05:54:08,133|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-02-09 05:54:08,187|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-02-09 05:54:08,188|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '8291c21f-5c33-4c2a-9ad4-e16a35d625e3', 'azureml.git.repository_uri': 'https://github.com/memasanz/email_parallelRun_classificationbatch_pipeline.git', 'mlflow.source.git.repoURL': 'https://github.com/memasanz/email_parallelRun_classificationbatch_pipeline.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '8f48c46db768dc633209fa56d4f78551a54a6c03', 'mlflow.source.git.commit': '8f48c46db768dc633209fa56d4f78551a54a6c03', 'azureml.git.dirty': 'True'}\\n2022-02-09 05:54:08,188|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-02-09 05:54:08,391|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-02-09 05:54:08,391|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-02-09 05:54:08,392|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2022-02-09 05:54:08,393|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,397|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,402|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,403|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,403|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,403|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:08,403|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-02-09 05:54:11,281|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2022-02-09 05:54:11,281|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2022-02-09 05:54:11,282|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2022-02-09 05:54:11,329|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2022-02-09 05:54:11,329|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading path artifact\\n2022-02-09 05:54:11,329|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-02-09 05:54:11,329|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-02-09 05:54:11,658|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-02-09 05:54:11,658|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2022-02-09 05:54:11,721|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/outputs/email_classifier.pkl with size 150009, file size 150009.\\n2022-02-09 05:54:11,721|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf|INFO|complete is not setting status for submitted runs.\\n2022-02-09 05:54:11,721|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2022-02-09 05:54:11,721|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2022-02-09 05:54:11,721|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2022-02-09 05:54:11,722|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2022-02-09 05:54:11,722|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2022-02-09 05:54:11,722|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2022-02-09 05:54:11,722|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2022-02-09 05:54:11,722|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2022-02-09 05:54:11,722|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2022-02-09 05:54:11,722|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2022-02-09 05:54:11,722|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2022-02-09 05:54:11,723|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 4.\\n2022-02-09 05:54:11,723|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2022-02-09 05:54:11,723|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2022-02-09 05:54:11,723|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2022-02-09 05:54:11,723|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 4 values.\\n2022-02-09 05:54:11,724|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2022-02-09 05:54:11,724|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2022-02-09 05:54:11,724|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2022-02-09 05:54:11,724|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2022-02-09 05:54:11,724|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2022-02-09 05:54:11,725|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2022-02-09 05:54:11,725|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2022-02-09 05:54:11,729|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2022-02-09 05:54:11,730|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2022-02-09 05:54:11,730|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2022-02-09 05:54:11,730|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2022-02-09 05:54:11,730|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2022-02-09 05:54:11,730|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2022-02-09 05:54:11,730|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2022-02-09 05:54:11,730|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2022-02-09 05:54:11,730|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2022-02-09 05:54:12,006|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2022-02-09 05:54:12,231|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2022-02-09 05:54:12,231|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2022-02-09 05:54:12,231|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2022-02-09 05:54:12,231|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 9.846687316894531e-05 seconds.\\nWaiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.25047731399536133 seconds.\\n\\n2022-02-09 05:54:12,231|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2022-02-09 05:54:12,231|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2022-02-09 05:54:12,232|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2022-02-09 05:54:12,232|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2022-02-09 05:54:12,278|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2022-02-09 05:54:16,911|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-02-09 05:54:16,911|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-02-09 05:54:17,070|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-02-09 05:54:17,112|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/logs/azureml/dataprep/backgroundProcess_Telemetry.log path: /tmp/azureml_runs/00_email_classification_model_1644386043_55e20ecf/logs/azureml/dataprep/backgroundProcess_Telemetry.log\\n2022-02-09 05:54:17,163|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/logs/azureml/dataprep/backgroundProcess.log path: /tmp/azureml_runs/00_email_classification_model_1644386043_55e20ecf/logs/azureml/dataprep/backgroundProcess.log\\n2022-02-09 05:54:17,163|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-02-09 05:54:17,164|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\n2022-02-09 05:54:17,164|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\n2022-02-09 05:54:17,164|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-02-09 05:54:17,168|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\n2022-02-09 05:54:17,169|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\n2022-02-09 05:54:17,169|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-02-09 05:54:17,174|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result|DEBUG|Using basic handler - no exception handling\\n2022-02-09 05:54:17,174|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 3_result to queue of approximate size: 3\\n2022-02-09 05:54:17,280|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2022-02-09 05:54:17,365|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2022-02-09 05:54:17,365|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2022-02-09 05:54:17,365|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient|DEBUG|Fetching files for prefix in ExperimentRun, dcid.00_email_classification_model_1644386043_55e20ecf, outputs/email_classifier.pkl\\n2022-02-09 05:54:17,366|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[START]\\n2022-02-09 05:54:17,366|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _execute_with_base_arguments\\n2022-02-09 05:54:17,366|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling list_sas_by_prefix with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/prefix/contentinfo/{origin}/{container}/{path}\\n2022-02-09 05:54:17,367|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix|DEBUG|Using basic handler - no exception handling\\n2022-02-09 05:54:17,369|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[STOP]\\n2022-02-09 05:54:17,370|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[START]\\n2022-02-09 05:54:17,370|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|Awaiter is ApiPagination\\n2022-02-09 05:54:17,476|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[STOP]\\n2022-02-09 05:54:17,476|azureml._restclient.clientbase|DEBUG|Found continuation_token field in DTO\\n2022-02-09 05:54:17,476|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.AssetsClient.create-async:False|DEBUG|[START]\\n2022-02-09 05:54:17,476|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.AssetsClient|DEBUG|ClientBase: Calling create with url /modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/assets\\n2022-02-09 05:54:17,597|azureml._SubmittedRun#00_email_classification_model_1644386043_55e20ecf.RunHistoryFacade.AssetsClient.create-async:False|DEBUG|[STOP]\\n2022-02-09 05:54:17,608|azureml.ModelsClient.register-async:False|DEBUG|[START]\\n2022-02-09 05:54:17,608|azureml.ModelsClient|DEBUG|ClientBase: Calling register with url /modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/models\\n2022-02-09 05:54:17,837|azureml.ModelsClient.register-async:False|DEBUG|[STOP]\\n2022-02-09 05:54:17,838|azureml.WorkspaceClient.get-async:False|DEBUG|[START]\\n2022-02-09 05:54:17,838|azureml.WorkspaceClient|DEBUG|ClientBase: Calling get with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}\\n2022-02-09 05:54:17,889|azureml.WorkspaceClient.get-async:False|DEBUG|[STOP]\\n2022-02-09 05:54:17,889|azureml.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-02-09 05:54:17,889|azureml.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-02-09 05:54:17,938|azureml.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-02-09 05:54:17,938|azureml.core.run|DEBUG|Available factories for run types {'azureml.scriptrun': <function ScriptRun._from_run_dto at 0x7f008051e488>}\\n2022-02-09 05:54:17,938|azureml.core.run|DEBUG|Initializing Run 00_email_classification_model_1644386043_55e20ecf from type azureml.scriptrun\\n2022-02-09 05:54:17,941|azureml.ScriptRun#00_email_classification_model_1644386043_55e20ecf|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '8291c21f-5c33-4c2a-9ad4-e16a35d625e3', 'azureml.git.repository_uri': 'https://github.com/memasanz/email_parallelRun_classificationbatch_pipeline.git', 'mlflow.source.git.repoURL': 'https://github.com/memasanz/email_parallelRun_classificationbatch_pipeline.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '8f48c46db768dc633209fa56d4f78551a54a6c03', 'mlflow.source.git.commit': '8f48c46db768dc633209fa56d4f78551a54a6c03', 'azureml.git.dirty': 'True'}\\n2022-02-09 05:54:17,941|azureml.ScriptRun#00_email_classification_model_1644386043_55e20ecf.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-02-09 05:54:18,022|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2022-02-09 05:54:18,022|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/00_email_classification_model_1644386043_55e20ecf\\n2022-02-09 05:54:18,022|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /tmp/azureml_runs/00_email_classification_model_1644386043_55e20ecf to /tmp/azureml_runs/00_email_classification_model_1644386043_55e20ecf\\n2022-02-09 05:54:18,022|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /tmp/azureml_runs/00_email_classification_model_1644386043_55e20ecf\\n2022-02-09 05:54:18,022|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2022-02-09 05:54:18,023|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2022-02-09 05:54:18,023|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\n2022-02-09 05:54:18,023|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2022-02-09 05:54:18,023|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\n2022-02-09 05:54:18,023|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is empty in dir ./outputs\\n2022-02-09 05:54:18,023|azureml.TrackFolders|DEBUG|[STOP]\\n2022-02-09 05:54:18,023|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\n2022-02-09 05:54:18,023|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\n2022-02-09 05:54:18,023|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\n2022-02-09 05:54:18,024|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-02-09 05:54:18,024|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result|DEBUG|Using basic handler - no exception handling\\n2022-02-09 05:54:18,024|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 4_result to queue of approximate size: 4\\n2022-02-09 05:54:18,027|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\n2022-02-09 05:54:18,028|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,028|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,029|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,030|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,031|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,031|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,032|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,032|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,032|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,033|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,033|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,033|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,033|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,034|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,034|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,034|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,035|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,035|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 05:54:18,037|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-02-09 05:54:18,037|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result|DEBUG|Using basic handler - no exception handling\\n2022-02-09 05:54:18,037|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 5_result to queue of approximate size: 5\\n2022-02-09 05:54:18,038|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\n2022-02-09 05:54:18,038|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\n2022-02-09 05:54:18,038|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\n2022-02-09 05:54:18,038|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\n2022-02-09 05:54:18,038|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result), AsyncTask(3_result), AsyncTask(4_result), AsyncTask(5_result)].\\n2022-02-09 05:54:18,038|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\n2022-02-09 05:54:18,038|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-02-09 05:54:18,038|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\n2022-02-09 05:54:18,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\n2022-02-09 05:54:18,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-02-09 05:54:18,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\n2022-02-09 05:54:18,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\n2022-02-09 05:54:18,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-02-09 05:54:18,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\n2022-02-09 05:54:18,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[START]\\n2022-02-09 05:54:18,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-02-09 05:54:18,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[STOP]\\n2022-02-09 05:54:18,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[START]\\n2022-02-09 05:54:18,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-02-09 05:54:18,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[STOP]\\n2022-02-09 05:54:18,290|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|[START]\\n2022-02-09 05:54:18,290|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-02-09 05:54:18,290|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|[STOP]\\n2022-02-09 05:54:18,290|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Waiting on task: 5_result.\\n1 tasks left. Current duration of flush 0.0016057491302490234 seconds.\\n\\n2022-02-09 05:54:18,290|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.37.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': '00_email_classification_model_1644386043_55e20ecf',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2022-02-09T05:54:04.956659Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '8291c21f-5c33-4c2a-9ad4-e16a35d625e3',\n",
       "  'azureml.git.repository_uri': 'https://github.com/memasanz/email_parallelRun_classificationbatch_pipeline.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/memasanz/email_parallelRun_classificationbatch_pipeline.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '8f48c46db768dc633209fa56d4f78551a54a6c03',\n",
       "  'mlflow.source.git.commit': '8f48c46db768dc633209fa56d4f78551a54a6c03',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'c12f8f53-9d05-4d12-b68d-7157c5b6b55e'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'classifier_training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--input-data', 'DatasetConsumptionConfig:training_data'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'training_data': {'dataLocation': {'dataset': {'id': 'c12f8f53-9d05-4d12-b68d-7157c5b6b55e',\n",
       "      'name': 'email_dataset',\n",
       "      'version': '1'},\n",
       "     'dataPath': None,\n",
       "     'uri': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'training_data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False,\n",
       "    'options': None}},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'email classification',\n",
       "   'version': 'Autosave_2022-02-09T05:47:01Z_68169feb',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'dependencies': ['python=3.6.2',\n",
       "      'scikit-learn',\n",
       "      'ipykernel',\n",
       "      'matplotlib',\n",
       "      'pandas',\n",
       "      'pip',\n",
       "      {'pip': ['azureml-defaults', 'pyarrow']}],\n",
       "     'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211124.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=bGL%2FzFvK%2B1SDRApePEnWA03WqNCGh9wgN6WOjKDMVi0%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T05%3A41%3A39Z&ske=2022-02-10T13%3A51%3A39Z&sks=b&skv=2019-07-07&st=2022-02-09T05%3A44%3A19Z&se=2022-02-09T13%3A54%3A19Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=PmDrP9oJGUbcICihkVgS0UaHDwliGPkt0%2Bk8pPIk0Mg%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T05%3A41%3A39Z&ske=2022-02-10T13%3A51%3A39Z&sks=b&skv=2019-07-07&st=2022-02-09T05%3A44%3A19Z&se=2022-02-09T13%3A54%3A19Z&sp=r',\n",
       "  'logs/azureml/22751_azureml.log': 'https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/logs/azureml/22751_azureml.log?sv=2019-07-07&sr=b&sig=NhO4kxSpe3PX4lU6G8TQGPq35LhrPhvrFvs1umkzmwY%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T05%3A37%3A09Z&ske=2022-02-10T13%3A47%3A09Z&sks=b&skv=2019-07-07&st=2022-02-09T05%3A44%3A19Z&se=2022-02-09T13%3A54%3A19Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=WNdOjjYWPJWhv7oReZVXgLzOI%2BPgKAotO8n9RSRCZ%2BA%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T05%3A37%3A09Z&ske=2022-02-10T13%3A47%3A09Z&sks=b&skv=2019-07-07&st=2022-02-09T05%3A44%3A19Z&se=2022-02-09T13%3A54%3A19Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644386043_55e20ecf/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=ORinErNLDUZ699D%2B%2FD3oxx%2FvEJRvKEbWqT3m50kY0Nk%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T05%3A37%3A09Z&ske=2022-02-10T13%3A47%3A09Z&sks=b&skv=2019-07-07&st=2022-02-09T05%3A44%3A19Z&se=2022-02-09T13%3A54%3A19Z&sp=r'},\n",
       " 'submittedBy': 'Megan Masanz'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azureml.core.runconfig\n",
    "from azureml.core import Environment, Experiment\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Get the training dataset\n",
    "email_training_ds = ws.datasets.get('email_dataset')\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=script_folder,\n",
    "                                script='classifier_training.py',\n",
    "                                arguments = [\n",
    "                                             '--input-data', email_training_ds.as_named_input('training_data')], # Reference to dataset\n",
    "                                environment=experiment_env) \n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = '00_email_classification_model'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
