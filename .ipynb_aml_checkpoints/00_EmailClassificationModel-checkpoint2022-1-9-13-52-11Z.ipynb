{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## This sample notebook shows creating an experiment to train a model for classification, the model will be registered and leveraged for inferencing"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SMS Spam Collection Dataset\n",
        "Source: https://www.kaggle.com/uciml/sms-spam-collection-dataset\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.38.0 to work with mlopsdev\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1644414060532
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1644414066865
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('./datasets/spamformodel.csv')\n",
        "inferecing_data = pd.read_csv('./datasets/spamformodel.csv')\n",
        "data.head(5)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "  labels                                               text\n0    ham  Go until jurong point, crazy.. Available only ...\n1    ham                      Ok lar... Joking wif u oni...\n2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3    ham  U dun say so early hor... U c already then say...\n4    ham  Nah I don't think he goes to usf, he lives aro...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1644414069778
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "       labels                    text\ncount    3000                    3000\nunique      2                    2851\ntop       ham  Sorry, I'll call later\nfreq     2591                      19",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3000</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2</td>\n      <td>2851</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>ham</td>\n      <td>Sorry, I'll call later</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>2591</td>\n      <td>19</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1644414075212
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder\n",
        "batch_folder = './batch-data'\n",
        "os.makedirs(batch_folder, exist_ok=True)\n",
        "print(\"Folder created!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Folder created!\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1644414078016
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "default_ds.upload_files(files=['./datasets/spamformodel.csv'], # Upload the diabetes csv files in /data\n",
        "                        target_path= 'spam-data', # Put it in a folder path in the datastore\n",
        "                        overwrite=True, # Replace existing files of the same name\n",
        "                        show_progress=True)\n",
        "    \n",
        "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'spam-data/spamformodel.csv'))\n",
        "\n",
        "try:\n",
        "    tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                        name='email_dataset',\n",
        "                                        description='email spam or ham data',\n",
        "                                        tags = {'format':'CSV'},\n",
        "                                        create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "# Display the first 20 rows as a Pandas dataframe\n",
        "tab_data_set.take(20).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\"datastore.upload_files\" is deprecated after version 1.0.69. Please use \"FileDatasetFactory.upload_directory\" instead. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 1 files\nUploading ./datasets/spamformodel.csv\nUploaded ./datasets/spamformodel.csv, 1 files out of an estimated total of 1\nUploaded 1 files\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "   labels                                               text\n0     ham  Go until jurong point, crazy.. Available only ...\n1     ham                      Ok lar... Joking wif u oni...\n2    spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3     ham  U dun say so early hor... U c already then say...\n4     ham  Nah I don't think he goes to usf, he lives aro...\n5    spam  FreeMsg Hey there darling it's been 3 week's n...\n6     ham  Even my brother is not like to speak with me. ...\n7     ham  As per your request 'Melle Melle (Oru Minnamin...\n8    spam  WINNER!! As a valued network customer you have...\n9    spam  Had your mobile 11 months or more? U R entitle...\n10    ham  I'm gonna be home soon and i don't want to tal...\n11   spam  SIX chances to win CASH! From 100 to 20,000 po...\n12   spam  URGENT! You have won a 1 week FREE membership ...\n13    ham  I've been searching for the right words to tha...\n14    ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n15   spam  XXXMobileMovieClub: To use your credit, click ...\n16    ham                         Oh k...i'm watching here:)\n17    ham  Eh u remember how 2 spell his name... Yes i di...\n18    ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...\n19   spam  England v Macedonia - dont miss the goals/team...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>spam</td>\n      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ham</td>\n      <td>Even my brother is not like to speak with me. ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ham</td>\n      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>spam</td>\n      <td>WINNER!! As a valued network customer you have...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>spam</td>\n      <td>Had your mobile 11 months or more? U R entitle...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ham</td>\n      <td>I'm gonna be home soon and i don't want to tal...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>spam</td>\n      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>spam</td>\n      <td>URGENT! You have won a 1 week FREE membership ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ham</td>\n      <td>I've been searching for the right words to tha...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ham</td>\n      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>spam</td>\n      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ham</td>\n      <td>Oh k...i'm watching here:)</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ham</td>\n      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ham</td>\n      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>spam</td>\n      <td>England v Macedonia - dont miss the goals/team...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1644414093042
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['text']\n",
        "Y = data['labels']"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1644414097674
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "transformed_vector = count_vectorizer.fit_transform(X)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1644414099145
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_vector.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "(3000, 6245)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1644414100755
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#word frequecy\n",
        "print(transformed_vector[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "  (0, 2550)\t1\n  (0, 5784)\t1\n  (0, 3124)\t1\n  (0, 4249)\t1\n  (0, 1641)\t1\n  (0, 894)\t1\n  (0, 3977)\t1\n  (0, 2928)\t1\n  (0, 1224)\t1\n  (0, 2604)\t1\n  (0, 6120)\t1\n  (0, 3214)\t1\n  (0, 1222)\t1\n  (0, 1431)\t1\n  (0, 5501)\t1\n  (0, 2581)\t1\n  (0, 727)\t1\n  (0, 5955)\t1\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1644414105561
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfid_transformer = TfidfTransformer() \n",
        "tfidf_vector = tfid_transformer.fit_transform(transformed_vector)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1644414107773
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tfidf score per document\n",
        "print(tfidf_vector[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "  (0, 6120)\t0.2194752986462319\n  (0, 5955)\t0.19473901783061617\n  (0, 5784)\t0.22793693965845888\n  (0, 5501)\t0.15784322212997065\n  (0, 4249)\t0.2506070193198575\n  (0, 3977)\t0.16363891047125267\n  (0, 3214)\t0.28050545509161845\n  (0, 3124)\t0.31525135382042524\n  (0, 2928)\t0.11038091843908045\n  (0, 2604)\t0.18889359811399475\n  (0, 2581)\t0.15874972350310806\n  (0, 2550)\t0.1538778038097993\n  (0, 1641)\t0.26268283838726564\n  (0, 1431)\t0.2735917909803556\n  (0, 1224)\t0.2735917909803556\n  (0, 1222)\t0.2998760486969354\n  (0, 894)\t0.2542211973750386\n  (0, 727)\t0.31525135382042524\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1644414112671
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(tfidf_vector, Y, test_size = 0.2)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1644414114970
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_classification(y_test, y_pred):\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True) #how many predictions correct %\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize = False)\n",
        "    prec = precision_score(y_test, y_pred, average = 'weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    \n",
        "    print('aacuracy count:', num_acc)\n",
        "    print('accuracy score:', acc)\n",
        "    print('precision:', prec)\n",
        "    print('recall:', recall)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1644414119539
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GaussianNB().fit(x_train.toarray(), y_train)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1644414121039
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(x_test.toarray())"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1644414122198
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_classification(y_test, y_pred)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "aacuracy count: 547\naccuracy score: 0.9116666666666666\nprecision: 0.9352229805427899\nrecall: 0.9116666666666666\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1644414123823
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Training Script"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "script_folder = os.path.join(os.getcwd(), \"train\")\n",
        "print(script_folder)\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/devbox/code/Users/babal/EmailClass/email_parallelRun_classificationbatch_pipeline/train\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1644414130718
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/classifier_training.py\n",
        "\n",
        "import argparse\n",
        "from azureml.core import Run\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def summarize_classification(y_test, y_pred, run):\n",
        "    acc = accuracy_score(y_test, y_pred, normalize=True) #how many predictions correct %\n",
        "    num_acc = accuracy_score(y_test, y_pred, normalize = False)\n",
        "    prec = precision_score(y_test, y_pred, average = 'weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    \n",
        "    run.log('acc count', num_acc)\n",
        "    run.log('Accuracy', acc)\n",
        "    run.log('prec', prec)\n",
        "    run.log('recall', recall)\n",
        "    \n",
        "    print('aacuracy count:', num_acc)\n",
        "    print('accuracy score:', acc)\n",
        "    print('precision:', prec)\n",
        "    print('recall:', recall)\n",
        "    \n",
        "\n",
        "\n",
        "def getRuntimeArgs():\n",
        "    # Get script arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    return args\n",
        "\n",
        "def model_train(ds_df, run):\n",
        "    \n",
        "    X = ds_df['text']\n",
        "    Y = ds_df['labels']\n",
        "    #sklearn pipeline\n",
        "    clf = Pipeline([\n",
        "                            ('count_vectorizer', CountVectorizer()),\n",
        "                            ('classifier', LogisticRegression(solver='lbfgs', max_iter=10000))\n",
        "                        ])\n",
        "    #output of convectorizer, feed to classifier\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
        "    print('type of x_test')\n",
        "    print(type(x_test))\n",
        "    model = clf.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "    \n",
        "    print('*************************')\n",
        "    print('model predictions:')\n",
        "    print(y_pred)\n",
        "    summarize_classification(y_test, y_pred, run)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    args = getRuntimeArgs()\n",
        "    \n",
        "    # Get the experiment run context\n",
        "    run = Run.get_context()\n",
        "    \n",
        "    dataset_dir = './dataset/'\n",
        "    os.makedirs(dataset_dir, exist_ok=True)\n",
        "    ws = run.experiment.workspace\n",
        "    print(ws)\n",
        "    \n",
        "    \n",
        "    print(\"Loading Data...\")\n",
        "    data = run.input_datasets['training_data'].to_pandas_dataframe()\n",
        "    \n",
        "    \n",
        "    print(data.columns)\n",
        "    lr = model_train(data, run)\n",
        "    \n",
        "    \n",
        "    # Save the trained model\n",
        "    model_file = 'email_classifier.pkl'\n",
        "    joblib.dump(value=lr, filename=model_file)\n",
        "    run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
        "\n",
        "    # Complete the run\n",
        "    run.complete()\n",
        "\n",
        "\n",
        "    # Register the model\n",
        "    run.register_model(model_path='outputs/email_classifier.pkl', model_name='email_classifier',\n",
        "                       tags={'Training context':'spam or ham'})\n",
        "\n",
        "    #print('Model trained and registered.')\n",
        " \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing /mnt/batch/tasks/shared/LS_root/mounts/clusters/devbox/code/Users/babal/EmailClass/email_parallelRun_classificationbatch_pipeline/train/classifier_training.py\n"
        }
      ],
      "execution_count": 19,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute, ComputeTarget\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "user = 'cpu'\n",
        "compute_name = user + \"-cluster\"\n",
        "print(compute_name)\n",
        "\n",
        "# checks to see if compute target already exists in workspace, else create it\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
        "except ComputeTargetException:\n",
        "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D13\",\n",
        "                                                   min_nodes=0, \n",
        "                                                   max_nodes=1)\n",
        "\n",
        "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=40)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "cpu-cluster\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1644414156119
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/experiment_env.yml\n",
        "name: experiment_env\n",
        "dependencies:\n",
        "  # The python interpreter version.\n",
        "  # Currently Azure ML only supports 3.5.2 and later.\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- ipykernel\n",
        "- matplotlib\n",
        "- pandas\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing /mnt/batch/tasks/shared/LS_root/mounts/clusters/devbox/code/Users/babal/EmailClass/email_parallelRun_classificationbatch_pipeline/train/experiment_env.yml\n"
        }
      ],
      "execution_count": 22,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "experiment_env = Environment.from_conda_specification(\"email classification\", script_folder + \"/experiment_env.yml\")\n",
        "\n",
        "# Let Azure ML manage dependencies\n",
        "experiment_env.python.user_managed_dependencies = False \n",
        "\n",
        "# Print the environment details\n",
        "print(experiment_env.name, 'defined.')\n",
        "print(experiment_env.python.conda_dependencies.serialize_to_string())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "email classification defined.\nname: experiment_env\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2\n- scikit-learn\n- ipykernel\n- matplotlib\n- pandas\n- pip\n- pip:\n  - azureml-defaults\n  - pyarrow\n\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1644414199305
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core.runconfig\n",
        "from azureml.core import Environment, Experiment\n",
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Get the training dataset\n",
        "email_training_ds = ws.datasets.get('email_dataset')\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=script_folder,\n",
        "                                script='classifier_training.py',\n",
        "                                arguments = [\n",
        "                                             '--input-data', email_training_ds.as_named_input('training_data')], # Reference to dataset\n",
        "                                environment=experiment_env) \n",
        "\n",
        "# submit the experiment\n",
        "experiment_name = '00_email_classification_model'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1968476b3dd74d48be0207e3c02296ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/00_email_classification_model_1644414207_7d64e672?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/mlopsdev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"00_email_classification_model_1644414207_7d64e672\", \"run_properties\": {\"run_id\": \"00_email_classification_model_1644414207_7d64e672\", \"created_utc\": \"2022-02-09T13:43:27.960686Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"922b361d-8a3f-45c1-83a7-c272fd00c792\", \"azureml.git.repository_uri\": \"https://github.com/balakreshnan/email_parallelRun_classificationbatch_pipeline.git\", \"mlflow.source.git.repoURL\": \"https://github.com/balakreshnan/email_parallelRun_classificationbatch_pipeline.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"186a6f3508e212248a2f60eb388da1c36a0ce6f1\", \"mlflow.source.git.commit\": \"186a6f3508e212248a2f60eb388da1c36a0ce6f1\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-02-09T13:43:58.965471Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=dbG0YhBSQaocxhvdD0B%2Bo9kMrZlOZOtqxVmy6q8eAAk%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T00%3A59%3A13Z&ske=2022-02-10T09%3A09%3A13Z&sks=b&skv=2019-07-07&st=2022-02-09T13%3A39%3A00Z&se=2022-02-09T21%3A49%3A00Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=6S362pXacUP8xtaErmIv9RD0nhLPeA0JX5iybLQMaQo%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T00%3A59%3A13Z&ske=2022-02-10T09%3A09%3A13Z&sks=b&skv=2019-07-07&st=2022-02-09T13%3A39%3A00Z&se=2022-02-09T21%3A49%3A00Z&sp=r\", \"logs/azureml/32284_azureml.log\": \"https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/logs/azureml/32284_azureml.log?sv=2019-07-07&sr=b&sig=kt3D7LkZkm%2Bovi1Z1yI6KX%2FC%2Fw6PGaoSiqWbt3U9nsw%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T00%3A59%3A13Z&ske=2022-02-10T09%3A09%3A13Z&sks=b&skv=2019-07-07&st=2022-02-09T13%3A38%3A50Z&se=2022-02-09T21%3A48%3A50Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=oM%2F8aPwefeZolvg8HSjxV9bPopZKzVzK4yjlKnGABy4%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T00%3A59%3A13Z&ske=2022-02-10T09%3A09%3A13Z&sks=b&skv=2019-07-07&st=2022-02-09T13%3A38%3A50Z&se=2022-02-09T21%3A48%3A50Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=%2BY69LRWUeQ%2B%2FOiIor6NmmMz5cDunmwhYRS7qUm%2B1pQw%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T00%3A59%3A13Z&ske=2022-02-10T09%3A09%3A13Z&sks=b&skv=2019-07-07&st=2022-02-09T13%3A38%3A50Z&se=2022-02-09T21%3A48%3A50Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/32284_azureml.log\"]], \"run_duration\": \"0:00:31\", \"run_number\": \"1644414207\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"acc count\", \"run_id\": \"00_email_classification_model_1644414207_7d64e672\", \"categories\": [0], \"series\": [{\"data\": [585]}]}, {\"name\": \"Accuracy\", \"run_id\": \"00_email_classification_model_1644414207_7d64e672\", \"categories\": [0], \"series\": [{\"data\": [0.975]}]}, {\"name\": \"prec\", \"run_id\": \"00_email_classification_model_1644414207_7d64e672\", \"categories\": [0], \"series\": [{\"data\": [0.9749258760107816]}]}, {\"name\": \"recall\", \"run_id\": \"00_email_classification_model_1644414207_7d64e672\", \"categories\": [0], \"series\": [{\"data\": [0.975]}]}], \"run_logs\": \"2022-02-09 13:43:32,463|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\n2022-02-09 13:43:32,468|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: none\\n2022-02-09 13:43:32,469|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2022-02-09 13:43:32,469|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2022-02-09 13:43:33,755|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fc702a5f1e0> for run source azureml.scriptrun\\n2022-02-09 13:43:33,756|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-02-09 13:43:33,756|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-02-09 13:43:33,767|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2022-02-09 13:43:33,774|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2022-02-09 13:43:33,774|azureml.core.authentication|DEBUG|Time to expire 1814393.22536 seconds\\n2022-02-09 13:43:33,774|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2022-02-09 13:43:33,774|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:33,775|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:33,775|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:33,775|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:33,775|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:33,775|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:33,775|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:34,678|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-02-09 13:43:34,678|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-02-09 13:43:34,735|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-02-09 13:43:34,736|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '922b361d-8a3f-45c1-83a7-c272fd00c792', 'azureml.git.repository_uri': 'https://github.com/balakreshnan/email_parallelRun_classificationbatch_pipeline.git', 'mlflow.source.git.repoURL': 'https://github.com/balakreshnan/email_parallelRun_classificationbatch_pipeline.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '186a6f3508e212248a2f60eb388da1c36a0ce6f1', 'mlflow.source.git.commit': '186a6f3508e212248a2f60eb388da1c36a0ce6f1', 'azureml.git.dirty': 'True'}\\n2022-02-09 13:43:34,736|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-02-09 13:43:34,736|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2022-02-09 13:43:34,736|azureml.WorkerPool|DEBUG|[START]\\n2022-02-09 13:43:34,736|azureml.SendRunKillSignal|DEBUG|[START]\\n2022-02-09 13:43:34,736|azureml.RunStatusContext|DEBUG|[START]\\n2022-02-09 13:43:34,736|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunContextManager.RunStatusContext|DEBUG|[START]\\n2022-02-09 13:43:34,736|azureml.MetricsClient|DEBUG|[START]\\n2022-02-09 13:43:34,736|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2022-02-09 13:43:34,736|azureml.ContentUploader|DEBUG|[START]\\n2022-02-09 13:43:34,737|azureml._history.utils.context_managers|DEBUG|starting file watcher\\n2022-02-09 13:43:34,737|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\n2022-02-09 13:43:34,737|azureml.TrackFolders|DEBUG|[START]\\n2022-02-09 13:43:34,738|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2022-02-09 13:43:34,738|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2022-02-09 13:43:34,738|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/00_email_classification_model_1644414207_7d64e672\\n2022-02-09 13:43:34,738|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2022-02-09 13:43:34,738|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /tmp/azureml_runs/00_email_classification_model_1644414207_7d64e672\\n2022-02-09 13:43:34,745|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-02-09 13:43:34,750|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-02-09 13:43:35,032|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-02-09 13:43:35,176|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/logs/azureml/32284_azureml.log path: /tmp/azureml_runs/00_email_classification_model_1644414207_7d64e672/logs/azureml/32284_azureml.log\\n2022-02-09 13:43:35,176|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-02-09 13:43:35,177|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\n2022-02-09 13:43:35,177|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\n2022-02-09 13:43:39,650|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-02-09 13:43:39,650|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-02-09 13:43:39,650|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2022-02-09 13:43:39,650|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:39,650|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:39,651|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:39,651|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:39,651|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:39,651|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:39,651|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:39,674|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-02-09 13:43:39,675|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-02-09 13:43:39,726|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-02-09 13:43:39,727|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '922b361d-8a3f-45c1-83a7-c272fd00c792', 'azureml.git.repository_uri': 'https://github.com/balakreshnan/email_parallelRun_classificationbatch_pipeline.git', 'mlflow.source.git.repoURL': 'https://github.com/balakreshnan/email_parallelRun_classificationbatch_pipeline.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '186a6f3508e212248a2f60eb388da1c36a0ce6f1', 'mlflow.source.git.commit': '186a6f3508e212248a2f60eb388da1c36a0ce6f1', 'azureml.git.dirty': 'True'}\\n2022-02-09 13:43:39,727|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-02-09 13:43:40,007|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-02-09 13:43:40,007|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-02-09 13:43:40,007|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2022-02-09 13:43:40,008|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:40,008|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:40,009|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:40,009|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:40,009|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:40,009|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:40,009|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://centralus.api.azureml.ms.\\n2022-02-09 13:43:44,988|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2022-02-09 13:43:44,989|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2022-02-09 13:43:44,989|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2022-02-09 13:43:45,023|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2022-02-09 13:43:45,023|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading path artifact\\n2022-02-09 13:43:45,023|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-02-09 13:43:45,023|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-02-09 13:43:45,177|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-02-09 13:43:45,178|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-02-09 13:43:45,182|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-02-09 13:43:45,182|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2022-02-09 13:43:45,251|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/outputs/email_classifier.pkl with size 149994, file size 149994.\\n2022-02-09 13:43:45,251|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672|INFO|complete is not setting status for submitted runs.\\n2022-02-09 13:43:45,251|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2022-02-09 13:43:45,251|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2022-02-09 13:43:45,252|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2022-02-09 13:43:45,252|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2022-02-09 13:43:45,252|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2022-02-09 13:43:45,252|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2022-02-09 13:43:45,252|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2022-02-09 13:43:45,252|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2022-02-09 13:43:45,252|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2022-02-09 13:43:45,252|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2022-02-09 13:43:45,252|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2022-02-09 13:43:45,253|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 4.\\n2022-02-09 13:43:45,253|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2022-02-09 13:43:45,253|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2022-02-09 13:43:45,253|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2022-02-09 13:43:45,253|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2022-02-09 13:43:45,253|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2022-02-09 13:43:45,253|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 4 values.\\n2022-02-09 13:43:45,253|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2022-02-09 13:43:45,253|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2022-02-09 13:43:45,254|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2022-02-09 13:43:45,254|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2022-02-09 13:43:45,254|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2022-02-09 13:43:45,254|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2022-02-09 13:43:45,396|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-02-09 13:43:45,468|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/logs/azureml/dataprep/backgroundProcess.log path: /tmp/azureml_runs/00_email_classification_model_1644414207_7d64e672/logs/azureml/dataprep/backgroundProcess.log\\n2022-02-09 13:43:45,504|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2022-02-09 13:43:45,504|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2022-02-09 13:43:45,505|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2022-02-09 13:43:45,505|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Waiting on task: 0__handle_batch.\\n1 tasks left. Current duration of flush 0.0002467632293701172 seconds.\\n\\n2022-02-09 13:43:45,505|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2022-02-09 13:43:45,505|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2022-02-09 13:43:45,505|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2022-02-09 13:43:45,505|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2022-02-09 13:43:45,524|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/logs/azureml/dataprep/backgroundProcess_Telemetry.log path: /tmp/azureml_runs/00_email_classification_model_1644414207_7d64e672/logs/azureml/dataprep/backgroundProcess_Telemetry.log\\n2022-02-09 13:43:45,524|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-02-09 13:43:45,524|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\n2022-02-09 13:43:45,524|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\n2022-02-09 13:43:45,524|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-02-09 13:43:45,526|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\n2022-02-09 13:43:45,526|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\n2022-02-09 13:43:45,526|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-02-09 13:43:45,529|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result|DEBUG|Using basic handler - no exception handling\\n2022-02-09 13:43:45,529|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 3_result to queue of approximate size: 3\\n2022-02-09 13:43:45,535|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2022-02-09 13:43:45,755|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2022-02-09 13:43:45,755|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2022-02-09 13:43:45,755|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2022-02-09 13:43:45,755|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 6.103515625e-05 seconds.\\n\\n2022-02-09 13:43:45,755|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2022-02-09 13:43:45,755|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2022-02-09 13:43:45,756|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2022-02-09 13:43:45,756|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2022-02-09 13:43:45,798|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2022-02-09 13:43:50,804|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2022-02-09 13:43:50,891|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2022-02-09 13:43:50,892|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2022-02-09 13:43:50,892|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient|DEBUG|Fetching files for prefix in ExperimentRun, dcid.00_email_classification_model_1644414207_7d64e672, outputs/email_classifier.pkl\\n2022-02-09 13:43:50,892|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[START]\\n2022-02-09 13:43:50,892|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _execute_with_base_arguments\\n2022-02-09 13:43:50,892|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling list_sas_by_prefix with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/prefix/contentinfo/{origin}/{container}/{path}\\n2022-02-09 13:43:50,894|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix|DEBUG|Using basic handler - no exception handling\\n2022-02-09 13:43:50,894|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[STOP]\\n2022-02-09 13:43:50,894|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[START]\\n2022-02-09 13:43:50,894|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|Awaiter is ApiPagination\\n2022-02-09 13:43:50,941|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[STOP]\\n2022-02-09 13:43:50,942|azureml._restclient.clientbase|DEBUG|Found continuation_token field in DTO\\n2022-02-09 13:43:50,942|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.AssetsClient.create-async:False|DEBUG|[START]\\n2022-02-09 13:43:50,942|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.AssetsClient|DEBUG|ClientBase: Calling create with url /modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/assets\\n2022-02-09 13:43:51,092|azureml._SubmittedRun#00_email_classification_model_1644414207_7d64e672.RunHistoryFacade.AssetsClient.create-async:False|DEBUG|[STOP]\\n2022-02-09 13:43:51,098|azureml.ModelsClient.register-async:False|DEBUG|[START]\\n2022-02-09 13:43:51,098|azureml.ModelsClient|DEBUG|ClientBase: Calling register with url /modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/models\\n2022-02-09 13:43:51,515|azureml.ModelsClient.register-async:False|DEBUG|[STOP]\\n2022-02-09 13:43:51,516|azureml.WorkspaceClient.get-async:False|DEBUG|[START]\\n2022-02-09 13:43:51,516|azureml.WorkspaceClient|DEBUG|ClientBase: Calling get with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}\\n2022-02-09 13:43:51,575|azureml.WorkspaceClient.get-async:False|DEBUG|[STOP]\\n2022-02-09 13:43:51,576|azureml.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-02-09 13:43:51,576|azureml.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-02-09 13:43:51,617|azureml.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-02-09 13:43:51,617|azureml.core.run|DEBUG|Available factories for run types {'azureml.scriptrun': <function ScriptRun._from_run_dto at 0x7fc702a5f1e0>}\\n2022-02-09 13:43:51,617|azureml.core.run|DEBUG|Initializing Run 00_email_classification_model_1644414207_7d64e672 from type azureml.scriptrun\\n2022-02-09 13:43:51,636|azureml.ScriptRun#00_email_classification_model_1644414207_7d64e672|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '922b361d-8a3f-45c1-83a7-c272fd00c792', 'azureml.git.repository_uri': 'https://github.com/balakreshnan/email_parallelRun_classificationbatch_pipeline.git', 'mlflow.source.git.repoURL': 'https://github.com/balakreshnan/email_parallelRun_classificationbatch_pipeline.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '186a6f3508e212248a2f60eb388da1c36a0ce6f1', 'mlflow.source.git.commit': '186a6f3508e212248a2f60eb388da1c36a0ce6f1', 'azureml.git.dirty': 'True'}\\n2022-02-09 13:43:51,636|azureml.ScriptRun#00_email_classification_model_1644414207_7d64e672.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-02-09 13:43:51,703|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2022-02-09 13:43:51,703|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/00_email_classification_model_1644414207_7d64e672\\n2022-02-09 13:43:51,703|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /tmp/azureml_runs/00_email_classification_model_1644414207_7d64e672 to /tmp/azureml_runs/00_email_classification_model_1644414207_7d64e672\\n2022-02-09 13:43:51,703|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /tmp/azureml_runs/00_email_classification_model_1644414207_7d64e672\\n2022-02-09 13:43:51,703|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2022-02-09 13:43:51,703|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2022-02-09 13:43:51,703|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\n2022-02-09 13:43:51,703|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2022-02-09 13:43:51,703|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\n2022-02-09 13:43:51,703|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is empty in dir ./outputs\\n2022-02-09 13:43:51,703|azureml.TrackFolders|DEBUG|[STOP]\\n2022-02-09 13:43:51,703|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\n2022-02-09 13:43:51,703|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\n2022-02-09 13:43:51,704|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\n2022-02-09 13:43:51,704|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-02-09 13:43:51,704|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result|DEBUG|Using basic handler - no exception handling\\n2022-02-09 13:43:51,704|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 4_result to queue of approximate size: 4\\n2022-02-09 13:43:51,705|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\n2022-02-09 13:43:51,705|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,707|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,708|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,708|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,708|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,708|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,708|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,709|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,709|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,709|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,709|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,709|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,709|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,710|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,710|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,710|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,710|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,710|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,711|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,711|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,711|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,711|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,711|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,712|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,712|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,712|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,712|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,712|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,713|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,713|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,713|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,713|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,713|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,713|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,714|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,714|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,714|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,714|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,714|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,715|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,715|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,715|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,715|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,715|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-02-09 13:43:51,716|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result|DEBUG|Using basic handler - no exception handling\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 5_result to queue of approximate size: 5\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result), AsyncTask(3_result), AsyncTask(4_result), AsyncTask(5_result)].\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-02-09 13:43:51,717|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\n2022-02-09 13:43:51,718|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[START]\\n2022-02-09 13:43:51,718|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-02-09 13:43:51,718|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[STOP]\\n2022-02-09 13:43:51,718|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[START]\\n2022-02-09 13:43:51,718|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-02-09 13:43:51,718|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[STOP]\\n2022-02-09 13:43:51,968|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|[START]\\n2022-02-09 13:43:51,968|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-02-09 13:43:51,968|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|[STOP]\\n2022-02-09 13:43:51,968|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Waiting on task: 5_result.\\n1 tasks left. Current duration of flush 0.00070953369140625 seconds.\\n\\n2022-02-09 13:43:51,968|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": true, \"log_level\": \"INFO\", \"sdk_version\": \"1.38.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "{'runId': '00_email_classification_model_1644414207_7d64e672',\n 'target': 'local',\n 'status': 'Finalizing',\n 'startTimeUtc': '2022-02-09T13:43:28.637661Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'local',\n  'ContentSnapshotId': '922b361d-8a3f-45c1-83a7-c272fd00c792',\n  'azureml.git.repository_uri': 'https://github.com/balakreshnan/email_parallelRun_classificationbatch_pipeline.git',\n  'mlflow.source.git.repoURL': 'https://github.com/balakreshnan/email_parallelRun_classificationbatch_pipeline.git',\n  'azureml.git.branch': 'master',\n  'mlflow.source.git.branch': 'master',\n  'azureml.git.commit': '186a6f3508e212248a2f60eb388da1c36a0ce6f1',\n  'mlflow.source.git.commit': '186a6f3508e212248a2f60eb388da1c36a0ce6f1',\n  'azureml.git.dirty': 'True'},\n 'inputDatasets': [{'dataset': {'id': '0c1e0736-e640-4425-9536-93a7a89d1a6d'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'classifier_training.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': ['--input-data', 'DatasetConsumptionConfig:training_data'],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'local',\n  'dataReferences': {},\n  'data': {'training_data': {'dataLocation': {'dataset': {'id': '0c1e0736-e640-4425-9536-93a7a89d1a6d',\n      'name': 'email_dataset',\n      'version': '1'},\n     'dataPath': None,\n     'uri': None},\n    'mechanism': 'Direct',\n    'environmentVariableName': 'training_data',\n    'pathOnCompute': None,\n    'overwrite': False,\n    'options': None}},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'email classification',\n   'version': 'Autosave_2022-02-09T13:43:27Z_70789ef7',\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'dependencies': ['python=3.6.2',\n      'scikit-learn',\n      'ipykernel',\n      'matplotlib',\n      'pandas',\n      'pip',\n      {'pip': ['azureml-defaults', 'pyarrow']}],\n     'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': 'pytorch-1.7.0',\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': False,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'azureml-logs/60_control_log.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=vKK9Z4hd9TqhWs4tHaboiGb%2F18Lzic%2BwEGhLEUTjM%2BQ%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T13%3A33%3A45Z&ske=2022-02-10T21%3A43%3A45Z&sks=b&skv=2019-07-07&st=2022-02-09T13%3A33%3A48Z&se=2022-02-09T21%3A43%3A48Z&sp=r',\n  'azureml-logs/70_driver_log.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=mViTiDyo3nr2Yb5neR2UTL%2FWJMBgyMA57hWIPZoNW4Y%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T13%3A33%3A45Z&ske=2022-02-10T21%3A43%3A45Z&sks=b&skv=2019-07-07&st=2022-02-09T13%3A33%3A48Z&se=2022-02-09T21%3A43%3A48Z&sp=r',\n  'logs/azureml/32284_azureml.log': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/logs/azureml/32284_azureml.log?sv=2019-07-07&sr=b&sig=dj7yS6YQkETmw5D862kO8Sz0E%2Bia7iADQsDkxa8k1uw%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T13%3A33%3A45Z&ske=2022-02-10T21%3A43%3A45Z&sks=b&skv=2019-07-07&st=2022-02-09T13%3A33%3A48Z&se=2022-02-09T21%3A43%3A48Z&sp=r',\n  'logs/azureml/dataprep/backgroundProcess.log': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=uiLW6AbJIlVBIEaX3%2F0hEWClW8vOFdt8%2BRQf37JbLfM%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T13%3A33%3A45Z&ske=2022-02-10T21%3A43%3A45Z&sks=b&skv=2019-07-07&st=2022-02-09T13%3A33%3A48Z&se=2022-02-09T21%3A43%3A48Z&sp=r',\n  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.00_email_classification_model_1644414207_7d64e672/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=7vjQlVRGkAhFzq9BC13Y%2BFFXXtcJSwqBk8FtXEZvsis%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T13%3A33%3A45Z&ske=2022-02-10T21%3A43%3A45Z&sks=b&skv=2019-07-07&st=2022-02-09T13%3A33%3A48Z&se=2022-02-09T21%3A43%3A48Z&sp=r'},\n 'submittedBy': 'Balamurugan Balakreshnan'}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1644414230643
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}