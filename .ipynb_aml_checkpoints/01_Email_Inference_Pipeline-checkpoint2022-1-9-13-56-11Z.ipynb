{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Azure ML - Sample Batch Prediction Pipeline\n",
        "- No parallel run step leveraged"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates creation and execution of an Azure ML pipeline designed to load data from a remote source, to make predictions against that data using a previously registered ML model, and finally save that data  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_folder = 'email-classification-inference-pipeline'\n",
        "cluster_name = \"cpu-cluster\""
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1644414773632
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Required Packages"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
        "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "from azureml.pipeline.core import PipelineParameter, PipelineData, PipelineEndpoint\n",
        "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1644414799312
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace, Dataset\n",
        "# Connect to AML Workspace\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))\n",
        "\n",
        "# Get the default datastore\n",
        "default_ds = ws.get_default_datastore()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.38.0 to work with mlopsdev\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1644414836072
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Create a folder for the pipeline step files\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "email-classification-inference-pipeline\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1644414881068
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to inference, we need a dataset to inference on, so we will load into the inference folder location our data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "default_ds.upload_files(files=['./datasets/spaminference.csv'], # Upload the diabetes csv files in /data\n",
        "                        target_path= 'spam-data', # Put it in a folder path in the datastore\n",
        "                        overwrite=True, # Replace existing files of the same name\n",
        "                        show_progress=True)\n",
        "    \n",
        "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'spam-data/spaminference.csv'))\n",
        "\n",
        "# Display the first 20 rows as a Pandas dataframe\n",
        "tab_data_set.take(20).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\"datastore.upload_files\" is deprecated after version 1.0.69. Please use \"FileDatasetFactory.upload_directory\" instead. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 1 files\nUploading ./datasets/spaminference.csv\nUploaded ./datasets/spaminference.csv, 1 files out of an estimated total of 1\nUploaded 1 files\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "   labels                                               text\n0    spam  This message is free. Welcome to the new & imp...\n1     ham         Excellent, I'll see what riley's plans are\n2     ham                         I will see in half an hour\n3    spam  You've won tkts to the EURO2004 CUP FINAL or å...\n4     ham                            Ew are you one of them?\n5     ham                     Also hi wesley how've you been\n6     ham  Ah you see. You have to be in the lingo. I wil...\n7    spam  Loan for any purpose å£500 - å£75,000. Homeown...\n8    spam  Update_Now - 12Mths Half Price Orange line ren...\n9     ham  Imagine Life WITHOUT ME... see.. How fast u ar...\n10    ham              Hm good morning, headache anyone? :-)\n11    ham  Yeah no probs - last night is obviously catchi...\n12   spam  FREE UNLIMITED HARDCORE PORN direct 2 your mob...\n13    ham     I might go 2 sch. Yar at e salon now v boring.\n14    ham   &lt;#&gt;  mins but i had to stop somewhere f...\n15    ham  &lt;#&gt;  is fast approaching. So, Wish u a v...\n16    ham  One of the joys in lifeis waking up each daywi...\n17    ham       I didn't get the second half of that message\n18    ham                 Wat time do u wan 2 meet me later?\n19    ham  I thank you so much for all you do with selfle...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>spam</td>\n      <td>This message is free. Welcome to the new &amp; imp...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Excellent, I'll see what riley's plans are</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ham</td>\n      <td>I will see in half an hour</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>spam</td>\n      <td>You've won tkts to the EURO2004 CUP FINAL or å...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Ew are you one of them?</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ham</td>\n      <td>Also hi wesley how've you been</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ham</td>\n      <td>Ah you see. You have to be in the lingo. I wil...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>spam</td>\n      <td>Loan for any purpose å£500 - å£75,000. Homeown...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>spam</td>\n      <td>Update_Now - 12Mths Half Price Orange line ren...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ham</td>\n      <td>Imagine Life WITHOUT ME... see.. How fast u ar...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ham</td>\n      <td>Hm good morning, headache anyone? :-)</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ham</td>\n      <td>Yeah no probs - last night is obviously catchi...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>spam</td>\n      <td>FREE UNLIMITED HARDCORE PORN direct 2 your mob...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ham</td>\n      <td>I might go 2 sch. Yar at e salon now v boring.</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ham</td>\n      <td>&amp;lt;#&amp;gt;  mins but i had to stop somewhere f...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ham</td>\n      <td>&amp;lt;#&amp;gt;  is fast approaching. So, Wish u a v...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ham</td>\n      <td>One of the joys in lifeis waking up each daywi...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ham</td>\n      <td>I didn't get the second half of that message</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ham</td>\n      <td>Wat time do u wan 2 meet me later?</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ham</td>\n      <td>I thank you so much for all you do with selfle...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1644414890009
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Compute Resources"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "print('trying to create: ' + cluster_name)\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2, idle_seconds_before_scaledown=1800)\n",
        "        compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        compute_target.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "trying to create: cpu-cluster\nFound existing cluster, use it.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1644414890301
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Configuration\n",
        "Create configuration for the running pipeline.  The RunConfiguration defines the environment used in the python steps"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "run_config = RunConfiguration()\n",
        "run_config.docker.use_docker = True\n",
        "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
        "run_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn','ipykernel','matplotlib','pandas','pip'],\n",
        "                                                                            pip_packages=['azureml-sdk','numpy', 'joblib', 'sklearn' ])"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1644414903932
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Output Datasets\n",
        "\n",
        "Below are the configuration for datasets that will be passed between steps in our pipelien.  Note, in all cases we specifiy the datastore that should hold the datasets and wheather they should be registered following step completion or not.  This can optionally be disabled by removing the register_on_complete() call\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "inferencing_dataset = OutputFileDatasetConfig(name= 'email_inferencing_dataset', destination=(default_ds, 'inferencing_dataset/{run-id}')).read_delimited_files().register_on_complete(name= 'email_inferencing_data')\n",
        "scored_dataset      = OutputFileDatasetConfig(name= 'email_scored_dataset', destination=(default_ds, 'scored_dataset/{run-id}')).read_delimited_files().register_on_complete(name= 'email_scored_data')"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1644414912173
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Pipeline Parameters\n",
        "\n",
        "PipelineParameter objects serve as variable inputs to an Azure ML pipeline and can be specified at runtime. Multiple pipeline parameters can be created and used. Included here are multiple sample pipeline parameters (get_data_param_*) to highlight how parameters can be passed into and consumed by various pipeline steps."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "inference_data_location_parm = PipelineParameter(name='inference_data_location', default_value= 'spam-data')\n",
        "model_name_parm              = PipelineParameter(name='model_name', default_value= 'email_classifier')\n",
        "get_data_param_2             = PipelineParameter(name='get_data_param_2', default_value='value_2')\n",
        "get_data_param_3             = PipelineParameter(name='get_data_param_3', default_value='value_3')"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1644414915320
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "folder_name = 'batch-inferencing'\n",
        "script_folder = os.path.join(os.getcwd(), folder_name)\n",
        "print(script_folder)\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/devbox/code/Users/babal/EmailClass/email_parallelRun_classificationbatch_pipeline/batch-inferencing\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1644414920497
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/get_inferencing_data.py\n",
        "\n",
        "  \n",
        "from azureml.core import Run, Workspace, Datastore, Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "import pandas as pd\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "#Parse input arguments\n",
        "parser = argparse.ArgumentParser(\"Get Inferencing Data\")\n",
        "parser.add_argument('--inference_data_location', type=str, required=True)\n",
        "parser.add_argument('--get_data_param_2', type=str, required=True)\n",
        "parser.add_argument('--get_data_param_3', type=str, required=True)\n",
        "parser.add_argument('--inferencing_dataset', dest='inferencing_dataset', required=True)\n",
        "\n",
        "# Note: the get_data_param args below are included only as an example of argument passing.\n",
        "# They are not consumed in the code sample shown here.\n",
        "args, _ = parser.parse_known_args()\n",
        "\n",
        "inference_data_location = args.inference_data_location\n",
        "get_data_param_2 = args.get_data_param_2\n",
        "get_data_param_3 = args.get_data_param_3\n",
        "inferencing_dataset = args.inferencing_dataset\n",
        "\n",
        "print(str(type(inferencing_dataset)))\n",
        "print(inferencing_dataset)\n",
        "\n",
        "#Get current run\n",
        "current_run = Run.get_context()\n",
        "\n",
        "#Get associated AML workspace\n",
        "ws = current_run.experiment.workspace\n",
        "\n",
        "#Get default datastore\n",
        "ds = ws.get_default_datastore()\n",
        "\n",
        "# Get the default datastore\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "#spam-data/spaminference.csv\n",
        "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, inference_data_location + '/spaminference.csv'))\n",
        "\n",
        "# Register the tabular dataset\n",
        "try:\n",
        "    tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name= 'email-tabular-dataset-raw',\n",
        "                                description='email data',\n",
        "                                tags = {'format':'csv'},\n",
        "                                create_new_version=True)\n",
        "    print('Dataset registered.')\n",
        "except Exception as ex:\n",
        "        print(ex)\n",
        "        \n",
        "df = tab_data_set.to_pandas_dataframe()\n",
        "\n",
        "print('dataset shape = ' + str(df.shape))\n",
        "print('saving inferencing data: ' + inferencing_dataset)\n",
        "\n",
        "# Save dataset for consumption in next pipeline step\n",
        "os.makedirs(inferencing_dataset, exist_ok=True)\n",
        "df.to_csv(os.path.join(inferencing_dataset, 'inferencing_data.csv'), index=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing /mnt/batch/tasks/shared/LS_root/mounts/clusters/devbox/code/Users/babal/EmailClass/email_parallelRun_classificationbatch_pipeline/batch-inferencing/get_inferencing_data.py\n"
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/score_inferencing_data.py\n",
        "\n",
        "from azureml.core import Run, Workspace, Datastore, Dataset\n",
        "from azureml.core.model import Model\n",
        "from azureml.data.datapath import DataPath\n",
        "import pandas as pd\n",
        "import os\n",
        "import argparse\n",
        "import joblib\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "from azureml.core.model import Model\n",
        "import time\n",
        "import pandas as pd\n",
        "import azureml.core\n",
        "from azureml.core import Workspace, Dataset\n",
        "import os\n",
        "import math\n",
        "\n",
        "\n",
        "# Parse input arguments\n",
        "parser = argparse.ArgumentParser(\"Score Inferencing Data\")\n",
        "parser.add_argument('--model_name_parm', type=str, required=True)\n",
        "parser.add_argument('--scored_dataset', dest='scored_dataset', required=True)\n",
        "\n",
        "args, _ = parser.parse_known_args()\n",
        "model_name = args.model_name_parm\n",
        "scored_dataset = args.scored_dataset\n",
        "\n",
        "# Get current run\n",
        "current_run = Run.get_context()\n",
        "\n",
        "# Get associated AML workspace\n",
        "ws = current_run.experiment.workspace\n",
        "\n",
        "# Get default datastore\n",
        "ds = ws.get_default_datastore()\n",
        "\n",
        "\n",
        "inferencing_dataset = current_run.input_datasets['email_inferencing_data']\n",
        "inferencing_data_df = inferencing_dataset.to_pandas_dataframe()\n",
        "\n",
        "\n",
        "print('inferencing data df shape:' + str(inferencing_data_df.shape))\n",
        "\n",
        "#drop columns not in model\n",
        "#X = data['text']\n",
        "col_list = ['text']\n",
        "inferencing_data_df = inferencing_data_df[col_list]\n",
        "\n",
        "print('model_name' + model_name)\n",
        "\n",
        "# Get model from workspace - the code below will always retrieve the latest version of the model; specific versions can be targeted.\n",
        "model_list = Model.list(ws, name=model_name, latest=True)\n",
        "model_path = model_list[0].download(exist_ok=True)\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "\n",
        "print(inferencing_data_df.shape)\n",
        "\n",
        "\n",
        "X = inferencing_data_df['text']\n",
        "# Make predictions with new dataframe\n",
        "predictions = model.predict(X)\n",
        "\n",
        "print('made predictions')\n",
        "\n",
        "print(predictions)\n",
        "\n",
        "\n",
        "inferencing_data_df['Predictions']=predictions\n",
        "\n",
        "print(inferencing_data_df.head(5))\n",
        "\n",
        "\n",
        "# Save scored dataset\n",
        "os.makedirs(scored_dataset, exist_ok=True)\n",
        "print(scored_dataset)\n",
        "\n",
        "os.makedirs(scored_dataset, exist_ok=True)\n",
        "print(scored_dataset)\n",
        "inferencing_data_df.to_csv(os.path.join(scored_dataset, 'scored_data.csv'), index=False)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing /mnt/batch/tasks/shared/LS_root/mounts/clusters/devbox/code/Users/babal/EmailClass/email_parallelRun_classificationbatch_pipeline/batch-inferencing/score_inferencing_data.py\n"
        }
      ],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/publish_scored_data.py\n",
        "\n",
        "from azureml.core import Run, Workspace, Datastore, Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "import pandas as pd\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "# Get current run\n",
        "current_run = Run.get_context()\n",
        "\n",
        "# Get associated AML workspace\n",
        "ws = current_run.experiment.workspace\n",
        "\n",
        "# Get default datastore\n",
        "ds = ws.get_default_datastore()\n",
        "\n",
        "# Get inferencing dataset\n",
        "scored_dataset = current_run.input_datasets['email_scored_data']\n",
        "scored_data_df = scored_dataset.to_pandas_dataframe()\n",
        "\n",
        "# Save dataset to ./outputs dir\n",
        "os.makedirs('./outputs', exist_ok=True)\n",
        "scored_data_df.to_csv(os.path.join('outputs', 'scored_data.csv'), index=False)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing /mnt/batch/tasks/shared/LS_root/mounts/clusters/devbox/code/Users/babal/EmailClass/email_parallelRun_classificationbatch_pipeline/batch-inferencing/publish_scored_data.py\n"
        }
      ],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "get_inferencing_data_step = PythonScriptStep(\n",
        "    name='Get Inferencing Data',\n",
        "    script_name='get_inferencing_data.py',\n",
        "    arguments=[\n",
        "        '--inference_data_location', inference_data_location_parm,\n",
        "        '--get_data_param_2', get_data_param_2,\n",
        "        '--get_data_param_3', get_data_param_3,\n",
        "        '--inferencing_dataset', inferencing_dataset\n",
        "    ],\n",
        "    outputs=[inferencing_dataset],\n",
        "    compute_target=compute_target,\n",
        "    source_directory=folder_name,\n",
        "    allow_reuse=False,\n",
        "    runconfig=run_config\n",
        ")\n",
        "\n",
        "score_inferencing_data_step = PythonScriptStep(\n",
        "    name='Score Inferencing Data',\n",
        "    script_name='score_inferencing_data.py',\n",
        "    arguments=[\n",
        "        '--model_name_parm', model_name_parm,\n",
        "        '--scored_dataset', scored_dataset\n",
        "    ],\n",
        "    inputs=[inferencing_dataset.as_input(name= 'email_inferencing_data')],\n",
        "    outputs=[scored_dataset],\n",
        "    compute_target=compute_target,\n",
        "    source_directory=folder_name,\n",
        "    allow_reuse=False,\n",
        "    runconfig=run_config\n",
        ")\n",
        "\n",
        "publish_scored_data_step = PythonScriptStep(\n",
        "    name='Publish Scored Data',\n",
        "    script_name='publish_scored_data.py',\n",
        "    inputs=[scored_dataset.as_input(name= 'email_scored_data')],\n",
        "    compute_target=compute_target,\n",
        "    source_directory=folder_name,\n",
        "    allow_reuse=False,\n",
        "    runconfig=run_config\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1644414942144
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Pipeline\n",
        "\n",
        "Create an Azure ML Pipeline by specifying the steps to be executed. Note: based on the dataset dependencies between steps, exection occurs logically such that no step will execute unless all of the necessary input datasets have been generated."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(workspace=ws, steps=[get_inferencing_data_step, score_inferencing_data_step, publish_scored_data_step])"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1644414947932
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = Experiment(ws,  '01-email-inference-pipeline')\n",
        "run = experiment.submit(pipeline)\n",
        "run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step Get Inferencing Data [1057e6ce][2a13c70a-51fe-4a40-82a1-20f3d50f79d8], (This step will run and generate new outputs)\nCreated step Score Inferencing Data [4e0019d7][c5b8fd26-54c1-4cbe-b44f-5758727e0690], (This step will run and generate new outputs)\nCreated step Publish Scored Data [c1389da1][a1d06f21-8203-40d8-9af2-396a654540da], (This step will run and generate new outputs)\nSubmitted PipelineRun cba94efa-f494-46d4-97f0-a377fccf7b48\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/cba94efa-f494-46d4-97f0-a377fccf7b48?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/mlopsdev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\nPipelineRunId: cba94efa-f494-46d4-97f0-a377fccf7b48\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/cba94efa-f494-46d4-97f0-a377fccf7b48?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/mlopsdev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\nThis usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\nPlease check for package conflicts in your python environment\n"
        }
      ],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Publish Pipeline\n",
        "\n",
        "Create a published version of pipeline that can be triggered via a REST API call"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# published_pipeline = pipeline.publish(name = 'Email Batch Inferencing Pipeline',\n",
        "#                                      description = 'Pipeline that generates batch predictions using a registered trained model.',\n",
        "#                                      continue_on_step_failure = False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# published_pipeline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# rest_endpoint = published_pipeline.endpoint\n",
        "# print(rest_endpoint)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "# interactive_auth = InteractiveLoginAuthentication()\n",
        "# auth_header = interactive_auth.get_authentication_header()\n",
        "# print('Authentication header ready.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "\n",
        "# rest_endpoint = published_pipeline.endpoint\n",
        "# response = requests.post(rest_endpoint, \n",
        "#                          headers=auth_header, \n",
        "#                          json={\"ExperimentName\": user + \"rest-api-diabetes-batch\"})\n",
        "# run_id = response.json()[\"Id\"]\n",
        "# run_id"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# from azureml.pipeline.core.run import PipelineRun\n",
        "# from azureml.widgets import RunDetails\n",
        "\n",
        "# published_pipeline_run = PipelineRun(ws.experiments[user + \"rest-api-diabetes-batch\"], run_id)\n",
        "\n",
        "# # Block until the run completes\n",
        "# published_pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}