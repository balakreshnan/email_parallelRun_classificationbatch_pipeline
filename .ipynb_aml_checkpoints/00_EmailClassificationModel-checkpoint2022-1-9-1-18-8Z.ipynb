{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this demo we will build a machine learning model to classify sms texts as ham or spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMS Spam Collection Dataset\n",
    "Source: https://www.kaggle.com/uciml/sms-spam-collection-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.36.0 to work with mm-aml\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./datasets/spamformodel.csv')\n",
    "inferecing_data = pd.read_csv('./datasets/spamformodel.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2591</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                    text\n",
       "count    3000                    3000\n",
       "unique      2                    2851\n",
       "top       ham  Sorry, I'll call later\n",
       "freq     2591                      19"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created!\n"
     ]
    }
   ],
   "source": [
    "# Create a folder\n",
    "batch_folder = './batch-data'\n",
    "os.makedirs(batch_folder, exist_ok=True)\n",
    "print(\"Folder created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# for key in inferecing_data.index.unique():\n",
    "#     print(key)\n",
    "#     df = inferecing_data.loc[key].to_frame()\n",
    "#     print(df.columns)\n",
    "#     df = df.rename(columns={key: \"text\"})\n",
    "#     print(df.columns)\n",
    "#     df.to_csv('./batch-data/' + '%d.csv' % int(key), header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #list files in directory for \n",
    "# import os\n",
    "# path = './batch-data/'\n",
    "# file_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_list.remove('.ipynb_checkpoints')\n",
    "# file_list.remove('.amlignore')\n",
    "# file_list.remove('.amlignore.amltmp')\n",
    "\n",
    "# files_to_upload = []\n",
    "\n",
    "# for f in file_list:\n",
    "#     files_to_upload.append(os.path.join(path, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./batch-data/3000.csv'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# files_to_upload[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add as registered dataset in AML\n",
    "# default_ds = ws.get_default_datastore()\n",
    "# default_ds.upload_files(files=files_to_upload, # Upload the diabetes csv files in /data\n",
    "#                        target_path='spam-data-inferencing/', # Put it in a folder path in the datastore\n",
    "#                        overwrite=True, # Replace existing files of the same name\n",
    "#                        show_progress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\n",
    "\n",
    "# Register a dataset for the input data\n",
    "batch_data_set = Dataset.File.from_files(path=(default_ds, 'spam-data-inferencing/'), validate=False)\n",
    "try:\n",
    "    batch_data_set = batch_data_set.register(workspace=ws, \n",
    "                                             name='spam-batch-data-inference',\n",
    "                                             description='inference batch data',\n",
    "                                             create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0     ham  Go until jurong point, crazy.. Available only ...\n",
       "1     ham                      Ok lar... Joking wif u oni...\n",
       "2    spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3     ham  U dun say so early hor... U c already then say...\n",
       "4     ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5    spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6     ham  Even my brother is not like to speak with me. ...\n",
       "7     ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8    spam  WINNER!! As a valued network customer you have...\n",
       "9    spam  Had your mobile 11 months or more? U R entitle...\n",
       "10    ham  I'm gonna be home soon and i don't want to tal...\n",
       "11   spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12   spam  URGENT! You have won a 1 week FREE membership ...\n",
       "13    ham  I've been searching for the right words to tha...\n",
       "14    ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15   spam  XXXMobileMovieClub: To use your credit, click ...\n",
       "16    ham                         Oh k...i'm watching here:)\n",
       "17    ham  Eh u remember how 2 spell his name... Yes i di...\n",
       "18    ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...\n",
       "19   spam  England v Macedonia - dont miss the goals/team..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'spam-data/spamformodel.csv'))\n",
    "\n",
    "try:\n",
    "    tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                        name='email_dataset',\n",
    "                                        description='email spam or ham data',\n",
    "                                        tags = {'format':'CSV'},\n",
    "                                        create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "# Display the first 20 rows as a Pandas dataframe\n",
    "tab_data_set.take(20).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "Y = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "transformed_vector = count_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 6245)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2550)\t1\n",
      "  (0, 5784)\t1\n",
      "  (0, 3124)\t1\n",
      "  (0, 4249)\t1\n",
      "  (0, 1641)\t1\n",
      "  (0, 894)\t1\n",
      "  (0, 3977)\t1\n",
      "  (0, 2928)\t1\n",
      "  (0, 1224)\t1\n",
      "  (0, 2604)\t1\n",
      "  (0, 6120)\t1\n",
      "  (0, 3214)\t1\n",
      "  (0, 1222)\t1\n",
      "  (0, 1431)\t1\n",
      "  (0, 5501)\t1\n",
      "  (0, 2581)\t1\n",
      "  (0, 727)\t1\n",
      "  (0, 5955)\t1\n"
     ]
    }
   ],
   "source": [
    "#word frequecy\n",
    "print(transformed_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_transformer = TfidfTransformer() \n",
    "tfidf_vector = tfid_transformer.fit_transform(transformed_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6120)\t0.2194752986462319\n",
      "  (0, 5955)\t0.19473901783061617\n",
      "  (0, 5784)\t0.22793693965845888\n",
      "  (0, 5501)\t0.15784322212997065\n",
      "  (0, 4249)\t0.2506070193198575\n",
      "  (0, 3977)\t0.16363891047125267\n",
      "  (0, 3214)\t0.28050545509161845\n",
      "  (0, 3124)\t0.31525135382042524\n",
      "  (0, 2928)\t0.11038091843908045\n",
      "  (0, 2604)\t0.18889359811399475\n",
      "  (0, 2581)\t0.15874972350310806\n",
      "  (0, 2550)\t0.1538778038097993\n",
      "  (0, 1641)\t0.26268283838726564\n",
      "  (0, 1431)\t0.2735917909803556\n",
      "  (0, 1224)\t0.2735917909803556\n",
      "  (0, 1222)\t0.2998760486969354\n",
      "  (0, 894)\t0.2542211973750386\n",
      "  (0, 727)\t0.31525135382042524\n"
     ]
    }
   ],
   "source": [
    "#tfidf score per document\n",
    "print(tfidf_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_vector, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_classification(y_test, y_pred):\n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True) #how many predictions correct %\n",
    "    num_acc = accuracy_score(y_test, y_pred, normalize = False)\n",
    "    prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print('aacuracy count:', num_acc)\n",
    "    print('accuracy score:', acc)\n",
    "    print('precision:', prec)\n",
    "    print('recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB().fit(x_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aacuracy count: 532\n",
      "accuracy score: 0.8866666666666667\n",
      "precision: 0.9070244737405159\n",
      "recall: 0.8866666666666667\n"
     ]
    }
   ],
   "source": [
    "summarize_classification(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz-clean/code/Users/memasanz/email-classification/train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"train\")\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz-clean/code/Users/memasanz/email-classification/train/classifier_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/classifier_training.py\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def summarize_classification(y_test, y_pred, run):\n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True) #how many predictions correct %\n",
    "    num_acc = accuracy_score(y_test, y_pred, normalize = False)\n",
    "    prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    run.log('acc count', num_acc)\n",
    "    run.log('Accuracy', acc)\n",
    "    run.log('prec', prec)\n",
    "    run.log('recall', recall)\n",
    "    \n",
    "    print('aacuracy count:', num_acc)\n",
    "    print('accuracy score:', acc)\n",
    "    print('precision:', prec)\n",
    "    print('recall:', recall)\n",
    "    \n",
    "\n",
    "# def summarize_classification2(model, x_test, y_test, run):\n",
    "#     y_hat = model.predict(x_test)\n",
    "#     acc = np.average(y_hat == y_test)\n",
    "#     print('Accuracy:', acc)\n",
    "#     run.log('Accuracy', np.float(acc))\n",
    "\n",
    "    #change labels to 1 and 0's for this to work\n",
    "    # calculate AUC\n",
    "#     y_scores = model.predict_proba(x_test)\n",
    "#     auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "#     print('AUC: ' + str(auc))\n",
    "#     run.log('AUC', np.float(auc))\n",
    "\n",
    "#     # plot ROC curve\n",
    "#     fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "#     fig = plt.figure(figsize=(6, 4))\n",
    "#     # Plot the diagonal 50% line\n",
    "#     plt.plot([0, 1], [0, 1], 'k--')\n",
    "#     # Plot the FPR and TPR achieved by our model\n",
    "#     plt.plot(fpr, tpr)\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title('ROC Curve')\n",
    "#     run.log_image(name = \"ROC\", plot = fig)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "def getRuntimeArgs():\n",
    "    # Get script arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "def model_train(ds_df, run):\n",
    "    \n",
    "    X = ds_df['text']\n",
    "    Y = ds_df['labels']\n",
    "    #sklearn pipeline\n",
    "    clf = Pipeline([\n",
    "                            ('count_vectorizer', CountVectorizer()),\n",
    "                            ('classifier', LogisticRegression(solver='lbfgs', max_iter=10000))\n",
    "                        ])\n",
    "    #output of convectorizer, feed to classifier\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "    print('type of x_test')\n",
    "    print(type(x_test))\n",
    "    model = clf.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    print('*************************')\n",
    "    print('model predictions:')\n",
    "    print(y_pred)\n",
    "    summarize_classification(y_test, y_pred, run)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = getRuntimeArgs()\n",
    "    \n",
    "    # Get the experiment run context\n",
    "    run = Run.get_context()\n",
    "    \n",
    "    dataset_dir = './dataset/'\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    ws = run.experiment.workspace\n",
    "    print(ws)\n",
    "    \n",
    "    \n",
    "    print(\"Loading Data...\")\n",
    "    data = run.input_datasets['training_data'].to_pandas_dataframe()\n",
    "    \n",
    "    \n",
    "    print(data.columns)\n",
    "    lr = model_train(data, run)\n",
    "    \n",
    "    \n",
    "    # Save the trained model\n",
    "    model_file = 'email_classifier.pkl'\n",
    "    joblib.dump(value=lr, filename=model_file)\n",
    "    run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
    "\n",
    "    # Complete the run\n",
    "    run.complete()\n",
    "\n",
    "\n",
    "    # Register the model\n",
    "    run.register_model(model_path='outputs/email_classifier.pkl', model_name='email_classifier',\n",
    "                       tags={'Training context':'spam or ham'})\n",
    "\n",
    "    #print('Model trained and registered.')\n",
    " \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mm-cluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "user = 'mm'\n",
    "compute_name = user + \"-cluster\"\n",
    "print(compute_name)\n",
    "\n",
    "# checks to see if compute target already exists in workspace, else create it\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
    "except ComputeTargetException:\n",
    "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D13\",\n",
    "                                                   min_nodes=0, \n",
    "                                                   max_nodes=1)\n",
    "\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz-clean/code/Users/memasanz/email-classification/train/experiment_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/experiment_env.yml\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email classification defined.\n",
      "name: experiment_env\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "- scikit-learn\n",
      "- ipykernel\n",
      "- matplotlib\n",
      "- pandas\n",
      "- pip\n",
      "- pip:\n",
      "  - azureml-defaults\n",
      "  - pyarrow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(\"email classification\", script_folder + \"/experiment_env.yml\")\n",
    "\n",
    "# Let Azure ML manage dependencies\n",
    "experiment_env.python.user_managed_dependencies = False \n",
    "\n",
    "# Print the environment details\n",
    "print(experiment_env.name, 'defined.')\n",
    "print(experiment_env.python.conda_dependencies.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3101b48f1028463da4e8c26fa79d76c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/mm-email-classification-model-build_1642116679_d741cd92?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-aml-rg/workspaces/mm-aml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"mm-email-classification-model-build_1642116679_d741cd92\", \"run_properties\": {\"run_id\": \"mm-email-classification-model-build_1642116679_d741cd92\", \"created_utc\": \"2022-01-13T23:31:20.6675Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"2888315b-dfed-49e7-9bb9-0bb65ccc8d76\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-01-13T23:33:03.906695Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=NeCmzSWnNfr0E%2FoE18%2BWEXf3SC9AMHNETP8WxYtislg%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-13T18%3A08%3A54Z&ske=2022-01-15T02%3A18%3A54Z&sks=b&skv=2019-07-07&st=2022-01-14T00%3A51%3A58Z&se=2022-01-14T09%3A01%3A58Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=tLTehOaqIIXnFDv%2BvxjTB%2FY31fU2upnVNybfAM0LhLQ%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-13T18%3A08%3A54Z&ske=2022-01-15T02%3A18%3A54Z&sks=b&skv=2019-07-07&st=2022-01-14T00%3A51%3A58Z&se=2022-01-14T09%3A01%3A58Z&sp=r\", \"logs/azureml/20959_azureml.log\": \"https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/logs/azureml/20959_azureml.log?sv=2019-07-07&sr=b&sig=tGWTTOdRvDOTtisfoMqshlnCKyBPiHhZgFMOc8eGLuY%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-13T18%3A03%3A36Z&ske=2022-01-15T02%3A13%3A36Z&sks=b&skv=2019-07-07&st=2022-01-14T00%3A51%3A57Z&se=2022-01-14T09%3A01%3A57Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=Iqt3TijrSRH98YbY1beqbCH8%2B85qrsE6NsvfTT12et0%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-13T18%3A03%3A36Z&ske=2022-01-15T02%3A13%3A36Z&sks=b&skv=2019-07-07&st=2022-01-14T00%3A51%3A57Z&se=2022-01-14T09%3A01%3A57Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=ptQ953g%2Fo1%2FW6u87GsiQIu5TGNVWc2CZ4WeBEChKpY4%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-13T18%3A03%3A36Z&ske=2022-01-15T02%3A13%3A36Z&sks=b&skv=2019-07-07&st=2022-01-14T00%3A51%3A57Z&se=2022-01-14T09%3A01%3A57Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/20959_azureml.log\"]], \"run_duration\": \"0:01:43\", \"run_number\": \"12\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"acc count\", \"run_id\": \"mm-email-classification-model-build_1642116679_d741cd92\", \"categories\": [0], \"series\": [{\"data\": [588]}]}, {\"name\": \"Accuracy\", \"run_id\": \"mm-email-classification-model-build_1642116679_d741cd92\", \"categories\": [0], \"series\": [{\"data\": [0.98]}]}, {\"name\": \"prec\", \"run_id\": \"mm-email-classification-model-build_1642116679_d741cd92\", \"categories\": [0], \"series\": [{\"data\": [0.9804562737642586]}]}, {\"name\": \"recall\", \"run_id\": \"mm-email-classification-model-build_1642116679_d741cd92\", \"categories\": [0], \"series\": [{\"data\": [0.98]}]}], \"run_logs\": \"2022-01-13 23:32:41,659|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\n2022-01-13 23:32:41,678|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: none\\n2022-01-13 23:32:41,678|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2022-01-13 23:32:41,678|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2022-01-13 23:32:42,197|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fc9839fa268> for run source azureml.scriptrun\\n2022-01-13 23:32:42,198|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-01-13 23:32:42,198|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-01-13 23:32:42,203|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2022-01-13 23:32:42,211|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2022-01-13 23:32:42,212|azureml.core.authentication|DEBUG|Time to expire 1814317.787916 seconds\\n2022-01-13 23:32:42,212|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2022-01-13 23:32:42,212|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:42,212|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:42,213|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:42,213|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:42,213|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:42,213|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:42,213|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:42,357|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-01-13 23:32:42,357|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-01-13 23:32:42,431|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-01-13 23:32:42,432|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '2888315b-dfed-49e7-9bb9-0bb65ccc8d76'}\\n2022-01-13 23:32:42,432|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-01-13 23:32:42,432|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2022-01-13 23:32:42,432|azureml.WorkerPool|DEBUG|[START]\\n2022-01-13 23:32:42,432|azureml.SendRunKillSignal|DEBUG|[START]\\n2022-01-13 23:32:42,433|azureml.RunStatusContext|DEBUG|[START]\\n2022-01-13 23:32:42,433|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunContextManager.RunStatusContext|DEBUG|[START]\\n2022-01-13 23:32:42,433|azureml.MetricsClient|DEBUG|[START]\\n2022-01-13 23:32:42,433|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2022-01-13 23:32:42,433|azureml.ContentUploader|DEBUG|[START]\\n2022-01-13 23:32:42,433|azureml._history.utils.context_managers|DEBUG|starting file watcher\\n2022-01-13 23:32:42,434|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\n2022-01-13 23:32:42,434|azureml.TrackFolders|DEBUG|[START]\\n2022-01-13 23:32:42,434|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2022-01-13 23:32:42,434|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2022-01-13 23:32:42,435|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/mm-email-classification-model-build_1642116679_d741cd92\\n2022-01-13 23:32:42,435|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2022-01-13 23:32:42,435|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /tmp/azureml_runs/mm-email-classification-model-build_1642116679_d741cd92\\n2022-01-13 23:32:42,447|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-01-13 23:32:42,447|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-01-13 23:32:42,636|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-01-13 23:32:42,753|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/logs/azureml/20959_azureml.log path: /tmp/azureml_runs/mm-email-classification-model-build_1642116679_d741cd92/logs/azureml/20959_azureml.log\\n2022-01-13 23:32:42,754|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-01-13 23:32:42,755|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\n2022-01-13 23:32:42,755|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\n2022-01-13 23:32:44,358|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-01-13 23:32:44,358|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-01-13 23:32:44,359|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2022-01-13 23:32:44,359|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,359|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,359|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,360|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,360|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,360|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,360|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,396|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-01-13 23:32:44,397|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-01-13 23:32:44,473|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-01-13 23:32:44,474|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '2888315b-dfed-49e7-9bb9-0bb65ccc8d76'}\\n2022-01-13 23:32:44,474|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-01-13 23:32:44,707|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-01-13 23:32:44,707|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-01-13 23:32:44,708|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2022-01-13 23:32:44,710|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,712|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,720|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,720|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,721|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,721|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:44,721|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-13 23:32:50,042|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2022-01-13 23:32:50,042|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2022-01-13 23:32:50,043|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2022-01-13 23:32:50,087|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2022-01-13 23:32:50,087|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading path artifact\\n2022-01-13 23:32:50,087|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-01-13 23:32:50,087|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-01-13 23:32:50,247|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-01-13 23:32:50,247|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2022-01-13 23:32:50,346|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/outputs/email_classifier.pkl with size 150092, file size 150092.\\n2022-01-13 23:32:50,347|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92|INFO|complete is not setting status for submitted runs.\\n2022-01-13 23:32:50,347|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2022-01-13 23:32:50,347|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2022-01-13 23:32:50,347|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2022-01-13 23:32:50,347|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2022-01-13 23:32:50,347|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2022-01-13 23:32:50,347|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2022-01-13 23:32:50,347|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2022-01-13 23:32:50,347|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2022-01-13 23:32:50,348|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2022-01-13 23:32:50,348|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2022-01-13 23:32:50,348|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2022-01-13 23:32:50,348|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 4.\\n2022-01-13 23:32:50,348|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2022-01-13 23:32:50,348|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2022-01-13 23:32:50,349|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2022-01-13 23:32:50,349|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2022-01-13 23:32:50,349|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2022-01-13 23:32:50,350|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2022-01-13 23:32:50,350|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2022-01-13 23:32:50,349|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 4 values.\\n2022-01-13 23:32:50,350|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2022-01-13 23:32:50,355|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2022-01-13 23:32:50,355|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2022-01-13 23:32:50,355|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2022-01-13 23:32:50,355|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2022-01-13 23:32:50,359|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2022-01-13 23:32:50,359|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2022-01-13 23:32:50,359|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2022-01-13 23:32:50,359|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2022-01-13 23:32:50,360|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2022-01-13 23:32:50,360|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2022-01-13 23:32:50,360|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2022-01-13 23:32:50,669|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2022-01-13 23:32:50,860|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2022-01-13 23:32:50,861|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2022-01-13 23:32:50,861|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2022-01-13 23:32:50,861|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 8.797645568847656e-05 seconds.\\nWaiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.2503790855407715 seconds.\\n\\n2022-01-13 23:32:50,861|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2022-01-13 23:32:50,861|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2022-01-13 23:32:50,861|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2022-01-13 23:32:50,861|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2022-01-13 23:32:50,913|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2022-01-13 23:32:52,756|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-01-13 23:32:52,756|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-01-13 23:32:53,058|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-01-13 23:32:53,128|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/logs/azureml/dataprep/backgroundProcess.log path: /tmp/azureml_runs/mm-email-classification-model-build_1642116679_d741cd92/logs/azureml/dataprep/backgroundProcess.log\\n2022-01-13 23:32:53,165|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/logs/azureml/dataprep/backgroundProcess_Telemetry.log path: /tmp/azureml_runs/mm-email-classification-model-build_1642116679_d741cd92/logs/azureml/dataprep/backgroundProcess_Telemetry.log\\n2022-01-13 23:32:53,165|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-01-13 23:32:53,166|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\n2022-01-13 23:32:53,166|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\n2022-01-13 23:32:53,166|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-01-13 23:32:53,167|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\n2022-01-13 23:32:53,167|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\n2022-01-13 23:32:53,178|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-01-13 23:32:53,182|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result|DEBUG|Using basic handler - no exception handling\\n2022-01-13 23:32:53,183|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 3_result to queue of approximate size: 3\\n2022-01-13 23:32:55,920|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2022-01-13 23:32:56,003|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2022-01-13 23:32:56,003|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2022-01-13 23:32:56,003|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient|DEBUG|Fetching files for prefix in ExperimentRun, dcid.mm-email-classification-model-build_1642116679_d741cd92, outputs/email_classifier.pkl\\n2022-01-13 23:32:56,004|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[START]\\n2022-01-13 23:32:56,004|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _execute_with_base_arguments\\n2022-01-13 23:32:56,004|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling list_sas_by_prefix with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/prefix/contentinfo/{origin}/{container}/{path}\\n2022-01-13 23:32:56,005|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix|DEBUG|Using basic handler - no exception handling\\n2022-01-13 23:32:56,005|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[STOP]\\n2022-01-13 23:32:56,005|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[START]\\n2022-01-13 23:32:56,005|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|Awaiter is ApiPagination\\n2022-01-13 23:32:56,126|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[STOP]\\n2022-01-13 23:32:56,126|azureml._restclient.clientbase|DEBUG|Found continuation_token field in DTO\\n2022-01-13 23:32:56,126|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.AssetsClient.create-async:False|DEBUG|[START]\\n2022-01-13 23:32:56,127|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.AssetsClient|DEBUG|ClientBase: Calling create with url /modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/assets\\n2022-01-13 23:32:56,249|azureml._SubmittedRun#mm-email-classification-model-build_1642116679_d741cd92.RunHistoryFacade.AssetsClient.create-async:False|DEBUG|[STOP]\\n2022-01-13 23:32:56,258|azureml.ModelsClient.register-async:False|DEBUG|[START]\\n2022-01-13 23:32:56,258|azureml.ModelsClient|DEBUG|ClientBase: Calling register with url /modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/models\\n2022-01-13 23:32:56,682|azureml.ModelsClient.register-async:False|DEBUG|[STOP]\\n2022-01-13 23:32:56,683|azureml.WorkspaceClient.get-async:False|DEBUG|[START]\\n2022-01-13 23:32:56,683|azureml.WorkspaceClient|DEBUG|ClientBase: Calling get with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}\\n2022-01-13 23:32:56,747|azureml.WorkspaceClient.get-async:False|DEBUG|[STOP]\\n2022-01-13 23:32:56,747|azureml.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-01-13 23:32:56,747|azureml.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-01-13 23:32:56,806|azureml.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-01-13 23:32:56,807|azureml.core.run|DEBUG|Available factories for run types {'azureml.scriptrun': <function ScriptRun._from_run_dto at 0x7fc9839fa268>}\\n2022-01-13 23:32:56,807|azureml.core.run|DEBUG|Initializing Run mm-email-classification-model-build_1642116679_d741cd92 from type azureml.scriptrun\\n2022-01-13 23:32:56,809|azureml.ScriptRun#mm-email-classification-model-build_1642116679_d741cd92|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '2888315b-dfed-49e7-9bb9-0bb65ccc8d76'}\\n2022-01-13 23:32:56,809|azureml.ScriptRun#mm-email-classification-model-build_1642116679_d741cd92.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-01-13 23:32:56,905|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2022-01-13 23:32:56,906|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/mm-email-classification-model-build_1642116679_d741cd92\\n2022-01-13 23:32:56,906|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /tmp/azureml_runs/mm-email-classification-model-build_1642116679_d741cd92 to /tmp/azureml_runs/mm-email-classification-model-build_1642116679_d741cd92\\n2022-01-13 23:32:56,906|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /tmp/azureml_runs/mm-email-classification-model-build_1642116679_d741cd92\\n2022-01-13 23:32:56,906|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2022-01-13 23:32:56,906|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2022-01-13 23:32:56,906|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\n2022-01-13 23:32:56,906|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2022-01-13 23:32:56,906|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\n2022-01-13 23:32:56,906|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is empty in dir ./outputs\\n2022-01-13 23:32:56,906|azureml.TrackFolders|DEBUG|[STOP]\\n2022-01-13 23:32:56,906|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\n2022-01-13 23:32:56,907|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\n2022-01-13 23:32:56,907|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\n2022-01-13 23:32:56,907|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-01-13 23:32:56,908|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result|DEBUG|Using basic handler - no exception handling\\n2022-01-13 23:32:56,908|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 4_result to queue of approximate size: 4\\n2022-01-13 23:32:56,908|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\n2022-01-13 23:32:56,908|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,914|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,914|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,915|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,915|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,915|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,915|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,916|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,916|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,916|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,916|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,917|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,917|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,917|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,917|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,918|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,918|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,918|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,918|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,919|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,919|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,919|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,919|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,920|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,920|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,920|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,920|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,921|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,921|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,921|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,921|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,922|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,922|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,922|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,922|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result), AsyncTask(3_result), AsyncTask(4_result)].\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-01-13 23:32:56,924|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\n2022-01-13 23:32:56,925|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[START]\\n2022-01-13 23:32:56,925|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-01-13 23:32:56,925|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[STOP]\\n2022-01-13 23:32:56,925|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[START]\\n2022-01-13 23:32:56,925|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-01-13 23:32:56,925|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[STOP]\\n2022-01-13 23:32:56,925|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|\\n2022-01-13 23:32:56,925|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.36.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'mm-email-classification-model-build_1642116679_d741cd92',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2022-01-13T23:32:40.840641Z',\n",
       " 'endTimeUtc': '2022-01-13T23:33:03.906695Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '2888315b-dfed-49e7-9bb9-0bb65ccc8d76'},\n",
       " 'inputDatasets': [{'dataset': {'id': '953aae9e-8638-4254-a26c-f81b426874a2'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'classifier_training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--input-data', 'DatasetConsumptionConfig:training_data'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'training_data': {'dataLocation': {'dataset': {'id': '953aae9e-8638-4254-a26c-f81b426874a2',\n",
       "      'name': 'email_dataset',\n",
       "      'version': '1'},\n",
       "     'dataPath': None,\n",
       "     'uri': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'training_data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False,\n",
       "    'options': None}},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'email classification',\n",
       "   'version': 'Autosave_2022-01-13T23:31:20Z_3bed9eb9',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'dependencies': ['python=3.6.2',\n",
       "      'scikit-learn',\n",
       "      'ipykernel',\n",
       "      'matplotlib',\n",
       "      'pandas',\n",
       "      'pip',\n",
       "      {'pip': ['azureml-defaults', 'pyarrow']}],\n",
       "     'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211029.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=rPbOR6gZ3pLAsmMFjQ6AUtgb31TCjHsiwjoqWZkfkMw%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-13T18%3A29%3A04Z&ske=2022-01-15T02%3A39%3A04Z&sks=b&skv=2019-07-07&st=2022-01-13T23%3A23%3A06Z&se=2022-01-14T07%3A33%3A06Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=Xo47EL1TLwq%2FYKxRfsTMGVvAo1kUxKyA%2B2Cs%2Fd9XYSk%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-13T18%3A29%3A04Z&ske=2022-01-15T02%3A39%3A04Z&sks=b&skv=2019-07-07&st=2022-01-13T23%3A23%3A06Z&se=2022-01-14T07%3A33%3A06Z&sp=r',\n",
       "  'logs/azureml/20959_azureml.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/logs/azureml/20959_azureml.log?sv=2019-07-07&sr=b&sig=FdaD06q8A%2F%2FiHfTR5JGLggs1F1OvJ66cJSdzHeGRBMc%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-13T18%3A24%3A57Z&ske=2022-01-15T02%3A34%3A57Z&sks=b&skv=2019-07-07&st=2022-01-13T23%3A22%3A59Z&se=2022-01-14T07%3A32%3A59Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=Z76vYD6djeM6tGRQTwyY5ukYjgEpFNtdqd1YcdpmLws%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-13T18%3A24%3A57Z&ske=2022-01-15T02%3A34%3A57Z&sks=b&skv=2019-07-07&st=2022-01-13T23%3A22%3A59Z&se=2022-01-14T07%3A32%3A59Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mmaml7489685591.blob.core.windows.net/azureml/ExperimentRun/dcid.mm-email-classification-model-build_1642116679_d741cd92/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=YuVD3Xjj90yfnVZk6rPaZuWyLYUCCukxOgX8DH5iOI4%3D&skoid=df057cdb-33ee-4949-b0a0-f29dd30edb46&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-13T18%3A24%3A57Z&ske=2022-01-15T02%3A34%3A57Z&sks=b&skv=2019-07-07&st=2022-01-13T23%3A22%3A59Z&se=2022-01-14T07%3A32%3A59Z&sp=r'},\n",
       " 'submittedBy': 'Megan Masanz'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azureml.core.runconfig\n",
    "from azureml.core import Environment, Experiment\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Get the training dataset\n",
    "email_training_ds = ws.datasets.get('email_dataset')\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=script_folder,\n",
    "                                script='classifier_training.py',\n",
    "                                arguments = [\n",
    "                                             '--input-data', email_training_ds.as_named_input('training_data')], # Reference to dataset\n",
    "                                environment=experiment_env) \n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = user + '-email-classification-model-build'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
