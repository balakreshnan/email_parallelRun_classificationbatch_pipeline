{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Azure ML - Sample Batch Prediction Pipeline\n",
        "- Parallel run step leveraged"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "import os, shutil\n",
        "import pandas as pd\n",
        "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
        "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "from azureml.pipeline.core import PipelineParameter, PipelineData, PipelineEndpoint\n",
        "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
        "from azureml.core.experiment import Experiment\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.38.0 to work with mlopsdev\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1644416841573
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "folder_name = 'batch-inferencing'\n",
        "script_folder = os.path.join(os.getcwd(), folder_name)\n",
        "print(script_folder)\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/devbox/code/Users/babal/EmailClass/email_parallelRun_classificationbatch_pipeline/batch-inferencing\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1644416846165
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get default datastore\n",
        "default_ds = ws.get_default_datastore()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1644416849590
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In order to batch inference the data and leverage the parallel run step, we want to break up the dataset.\n",
        "The code below will generate many files - and then register them in the default datastore under the spam-data-inferencing folder"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#spam-data-inferencing\n",
        "\n",
        "data = pd.read_csv('./datasets/spaminfernce.csv')\n",
        "data = data[['text']]\n",
        "\n",
        "# Create a folder\n",
        "batch_folder = './batch-data'\n",
        "os.makedirs(batch_folder, exist_ok=True)\n",
        "print(\"Folder created!\")\n",
        "\n",
        "# # Save each sample as a separate file\n",
        "# print(\"Saving files...\")\n",
        "# for i in range(100):\n",
        "#     sample[i].tofile(os.path.join(batch_folder, str(i+1) + '.csv'), sep=\",\")\n",
        "# print(\"files saved!\")\n",
        "\n",
        "k = 100\n",
        "size = 1\n",
        "\n",
        "for i in range(k):\n",
        "    df = data[size*i:size*(i+1)]\n",
        "    df.to_csv(f'./batch-data/{i+1}.csv', index=False)\n",
        "    \n",
        "print('files created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Folder created!\nfiles created\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1644416863125
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the files to the default datastore\n",
        "print(\"Uploading files to datastore...\")\n",
        "default_ds = ws.get_default_datastore()\n",
        "default_ds.upload(src_dir=\"batch-data\", target_path=\"spam-data-inferencing\", overwrite=True, show_progress=True)\n",
        "\n",
        "# Register a dataset for the input data\n",
        "batch_data_set = Dataset.File.from_files(path=(default_ds, 'spam-data-inferencing/*.csv'), validate=False)\n",
        "try:\n",
        "    batch_data_set = batch_data_set.register(workspace=ws, \n",
        "                                             name='spam-batch-data-inference',\n",
        "                                             description='inference batch data',\n",
        "                                             create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading files to datastore...\nUploading an estimated of 100 files\nUploading batch-data/1.csv\nUploaded batch-data/1.csv, 1 files out of an estimated total of 100\nUploading batch-data/100.csv\nUploaded batch-data/100.csv, 2 files out of an estimated total of 100\nUploading batch-data/12.csv\nUploaded batch-data/12.csv, 3 files out of an estimated total of 100\nUploading batch-data/13.csv\nUploaded batch-data/13.csv, 4 files out of an estimated total of 100\nUploading batch-data/15.csv\nUploaded batch-data/15.csv, 5 files out of an estimated total of 100\nUploading batch-data/16.csv\nUploaded batch-data/16.csv, 6 files out of an estimated total of 100\nUploading batch-data/19.csv\nUploaded batch-data/19.csv, 7 files out of an estimated total of 100\nUploading batch-data/21.csv\nUploaded batch-data/21.csv, 8 files out of an estimated total of 100\nUploading batch-data/24.csv\nUploaded batch-data/24.csv, 9 files out of an estimated total of 100\nUploading batch-data/27.csv\nUploaded batch-data/27.csv, 10 files out of an estimated total of 100\nUploading batch-data/28.csv\nUploaded batch-data/28.csv, 11 files out of an estimated total of 100\nUploading batch-data/31.csv\nUploaded batch-data/31.csv, 12 files out of an estimated total of 100\nUploading batch-data/33.csv\nUploaded batch-data/33.csv, 13 files out of an estimated total of 100\nUploading batch-data/38.csv\nUploaded batch-data/38.csv, 14 files out of an estimated total of 100\nUploading batch-data/39.csv\nUploaded batch-data/39.csv, 15 files out of an estimated total of 100\nUploading batch-data/69.csv\nUploaded batch-data/69.csv, 16 files out of an estimated total of 100\nUploading batch-data/10.csv\nUploaded batch-data/10.csv, 17 files out of an estimated total of 100\nUploading batch-data/11.csv\nUploaded batch-data/11.csv, 18 files out of an estimated total of 100\nUploading batch-data/14.csv\nUploaded batch-data/14.csv, 19 files out of an estimated total of 100\nUploading batch-data/17.csv\nUploaded batch-data/17.csv, 20 files out of an estimated total of 100\nUploading batch-data/18.csv\nUploaded batch-data/18.csv, 21 files out of an estimated total of 100\nUploading batch-data/2.csv\nUploaded batch-data/2.csv, 22 files out of an estimated total of 100\nUploading batch-data/20.csv\nUploaded batch-data/20.csv, 23 files out of an estimated total of 100\nUploading batch-data/22.csv\nUploaded batch-data/22.csv, 24 files out of an estimated total of 100\nUploading batch-data/23.csv\nUploaded batch-data/23.csv, 25 files out of an estimated total of 100\nUploading batch-data/25.csv\nUploaded batch-data/25.csv, 26 files out of an estimated total of 100\nUploading batch-data/26.csv\nUploaded batch-data/26.csv, 27 files out of an estimated total of 100\nUploading batch-data/29.csv\nUploaded batch-data/29.csv, 28 files out of an estimated total of 100\nUploading batch-data/3.csv\nUploaded batch-data/3.csv, 29 files out of an estimated total of 100\nUploading batch-data/30.csv\nUploaded batch-data/30.csv, 30 files out of an estimated total of 100\nUploading batch-data/32.csv\nUploaded batch-data/32.csv, 31 files out of an estimated total of 100\nUploading batch-data/34.csv\nUploaded batch-data/34.csv, 32 files out of an estimated total of 100\nUploading batch-data/35.csv\nUploaded batch-data/35.csv, 33 files out of an estimated total of 100\nUploading batch-data/36.csv\nUploaded batch-data/36.csv, 34 files out of an estimated total of 100\nUploading batch-data/37.csv\nUploaded batch-data/37.csv, 35 files out of an estimated total of 100\nUploading batch-data/4.csv\nUploaded batch-data/4.csv, 36 files out of an estimated total of 100\nUploading batch-data/40.csv\nUploaded batch-data/40.csv, 37 files out of an estimated total of 100\nUploading batch-data/41.csv\nUploaded batch-data/41.csv, 38 files out of an estimated total of 100\nUploading batch-data/42.csv\nUploaded batch-data/42.csv, 39 files out of an estimated total of 100\nUploading batch-data/43.csv\nUploaded batch-data/43.csv, 40 files out of an estimated total of 100\nUploading batch-data/44.csv\nUploaded batch-data/44.csv, 41 files out of an estimated total of 100\nUploading batch-data/45.csv\nUploaded batch-data/45.csv, 42 files out of an estimated total of 100\nUploading batch-data/46.csv\nUploaded batch-data/46.csv, 43 files out of an estimated total of 100\nUploading batch-data/47.csv\nUploaded batch-data/47.csv, 44 files out of an estimated total of 100\nUploading batch-data/48.csv\nUploaded batch-data/48.csv, 45 files out of an estimated total of 100\nUploading batch-data/49.csv\nUploaded batch-data/49.csv, 46 files out of an estimated total of 100\nUploading batch-data/5.csv\nUploaded batch-data/5.csv, 47 files out of an estimated total of 100\nUploading batch-data/50.csv\nUploaded batch-data/50.csv, 48 files out of an estimated total of 100\nUploading batch-data/51.csv\nUploaded batch-data/51.csv, 49 files out of an estimated total of 100\nUploading batch-data/52.csv\nUploaded batch-data/52.csv, 50 files out of an estimated total of 100\nUploading batch-data/53.csv\nUploaded batch-data/53.csv, 51 files out of an estimated total of 100\nUploading batch-data/54.csv\nUploaded batch-data/54.csv, 52 files out of an estimated total of 100\nUploading batch-data/55.csv\nUploaded batch-data/55.csv, 53 files out of an estimated total of 100\nUploading batch-data/56.csv\nUploaded batch-data/56.csv, 54 files out of an estimated total of 100\nUploading batch-data/57.csv\nUploaded batch-data/57.csv, 55 files out of an estimated total of 100\nUploading batch-data/58.csv\nUploaded batch-data/58.csv, 56 files out of an estimated total of 100\nUploading batch-data/59.csv\nUploaded batch-data/59.csv, 57 files out of an estimated total of 100\nUploading batch-data/6.csv\nUploaded batch-data/6.csv, 58 files out of an estimated total of 100\nUploading batch-data/60.csv\nUploaded batch-data/60.csv, 59 files out of an estimated total of 100\nUploading batch-data/61.csv\nUploaded batch-data/61.csv, 60 files out of an estimated total of 100\nUploading batch-data/62.csv\nUploaded batch-data/62.csv, 61 files out of an estimated total of 100\nUploading batch-data/63.csv\nUploaded batch-data/63.csv, 62 files out of an estimated total of 100\nUploading batch-data/64.csv\nUploaded batch-data/64.csv, 63 files out of an estimated total of 100\nUploading batch-data/65.csv\nUploaded batch-data/65.csv, 64 files out of an estimated total of 100\nUploading batch-data/66.csv\nUploaded batch-data/66.csv, 65 files out of an estimated total of 100\nUploading batch-data/67.csv\nUploaded batch-data/67.csv, 66 files out of an estimated total of 100\nUploading batch-data/68.csv\nUploaded batch-data/68.csv, 67 files out of an estimated total of 100\nUploading batch-data/7.csv\nUploaded batch-data/7.csv, 68 files out of an estimated total of 100\nUploading batch-data/70.csv\nUploaded batch-data/70.csv, 69 files out of an estimated total of 100\nUploading batch-data/71.csv\nUploaded batch-data/71.csv, 70 files out of an estimated total of 100\nUploading batch-data/72.csv\nUploaded batch-data/72.csv, 71 files out of an estimated total of 100\nUploading batch-data/73.csv\nUploaded batch-data/73.csv, 72 files out of an estimated total of 100\nUploading batch-data/74.csv\nUploaded batch-data/74.csv, 73 files out of an estimated total of 100\nUploading batch-data/75.csv\nUploaded batch-data/75.csv, 74 files out of an estimated total of 100\nUploading batch-data/76.csv\nUploaded batch-data/76.csv, 75 files out of an estimated total of 100\nUploading batch-data/77.csv\nUploaded batch-data/77.csv, 76 files out of an estimated total of 100\nUploading batch-data/78.csv\nUploaded batch-data/78.csv, 77 files out of an estimated total of 100\nUploading batch-data/79.csv\nUploaded batch-data/79.csv, 78 files out of an estimated total of 100\nUploading batch-data/8.csv\nUploaded batch-data/8.csv, 79 files out of an estimated total of 100\nUploading batch-data/80.csv\nUploaded batch-data/80.csv, 80 files out of an estimated total of 100\nUploading batch-data/81.csv\nUploaded batch-data/81.csv, 81 files out of an estimated total of 100\nUploading batch-data/82.csv\nUploaded batch-data/82.csv, 82 files out of an estimated total of 100\nUploading batch-data/83.csv\nUploaded batch-data/83.csv, 83 files out of an estimated total of 100\nUploading batch-data/84.csv\nUploaded batch-data/84.csv, 84 files out of an estimated total of 100\nUploading batch-data/85.csv\nUploaded batch-data/85.csv, 85 files out of an estimated total of 100\nUploading batch-data/86.csv\nUploaded batch-data/86.csv, 86 files out of an estimated total of 100\nUploading batch-data/87.csv\nUploaded batch-data/87.csv, 87 files out of an estimated total of 100\nUploading batch-data/88.csv\nUploaded batch-data/88.csv, 88 files out of an estimated total of 100\nUploading batch-data/89.csv\nUploaded batch-data/89.csv, 89 files out of an estimated total of 100\nUploading batch-data/9.csv\nUploaded batch-data/9.csv, 90 files out of an estimated total of 100\nUploading batch-data/90.csv\nUploaded batch-data/90.csv, 91 files out of an estimated total of 100\nUploading batch-data/91.csv\nUploaded batch-data/91.csv, 92 files out of an estimated total of 100\nUploading batch-data/92.csv\nUploaded batch-data/92.csv, 93 files out of an estimated total of 100\nUploading batch-data/93.csv\nUploaded batch-data/93.csv, 94 files out of an estimated total of 100\nUploading batch-data/94.csv\nUploaded batch-data/94.csv, 95 files out of an estimated total of 100\nUploading batch-data/95.csv\nUploaded batch-data/95.csv, 96 files out of an estimated total of 100\nUploading batch-data/96.csv\nUploaded batch-data/96.csv, 97 files out of an estimated total of 100\nUploading batch-data/97.csv\nUploaded batch-data/97.csv, 98 files out of an estimated total of 100\nUploading batch-data/98.csv\nUploaded batch-data/98.csv, 99 files out of an estimated total of 100\nUploading batch-data/99.csv\nUploaded batch-data/99.csv, 100 files out of an estimated total of 100\nUploaded 100 files\nDone!\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1644416874522
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Cluster"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute, ComputeTarget\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "\n",
        "compute_name =  \"email-cluster\"\n",
        "print(compute_name)\n",
        "\n",
        "# checks to see if compute target already exists in workspace, else create it\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
        "except ComputeTargetException:\n",
        "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D13_V2\",\n",
        "                                                   min_nodes=0, \n",
        "                                                   max_nodes=5)\n",
        "\n",
        "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=120)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "email-cluster\nInProgress.\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1644416884454
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/email_classification_inference.yml\n",
        "name: email_classification_inference\n",
        "dependencies:\n",
        "  # The python interpreter version.\n",
        "  # Currently Azure ML only supports 3.5.2 and later.\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- ipykernel\n",
        "- matplotlib\n",
        "- pandas\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing /mnt/batch/tasks/shared/LS_root/mounts/clusters/devbox/code/Users/babal/EmailClass/email_parallelRun_classificationbatch_pipeline/batch-inferencing/email_classification_inference.yml\n"
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
        "\n",
        "# Create an Environment for the experiment\n",
        "batch_env = Environment.from_conda_specification(\"email_classification_inference\", script_folder + \"/email_classification_inference.yml\")\n",
        "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\n",
        "print('Configuration ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Configuration ready.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1644416893635
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Pipeline Parameters\n",
        "\n",
        "PipelineParameter objects serve as variable inputs to an Azure ML pipeline and can be specified at runtime. Below we specify a pipeline parameter object model_name which will be used to reference the locally trained model that was uploaded and registered within the Azure ML workspace. Multiple pipeline parameters can be created and used. Included here are multiple sample pipeline parameters (get_data_param_*) to highlight how parameters can be passed into and consumed by various pipeline steps."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = PipelineParameter(name='model_name', default_value='email_classifier')"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1644416896113
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Pipeline Steps\n",
        "\n",
        "The pipeline below consists of steps to gather and register data from a remote source, a scoring step where the registered model is used to make predictions on loaded, and a data publish step where scored data can be exported to a remote data source. All of the PythonScriptSteps have a corresponding *.py file which is referenced in the step arguments. Also, any PipelineParameters defined above can be passed to and consumed within these steps.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "folder_name = 'batch-inferencing'\n",
        "script_folder = os.path.join(os.getcwd(), folder_name)\n",
        "print(script_folder)\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/devbox/code/Users/babal/EmailClass/email_parallelRun_classificationbatch_pipeline/batch-inferencing\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1644416901229
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/batch_inferencing_data.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from azureml.core import Model\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "def init():\n",
        "    # Runs when the pipeline step is initialized\n",
        "    global model\n",
        "\n",
        "    # load the model\n",
        "    print('****loaded model**********')\n",
        "    model_path = Model.get_model_path('email_classifier')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "\n",
        "def run(mini_batch):\n",
        "    # This runs for each batch\n",
        "    print(f'run method start: {__file__}, run({mini_batch})')\n",
        "    resultList = []\n",
        "    print('type of mini batch')\n",
        "    print(str(type(mini_batch)))\n",
        "    # process each file in the batch\n",
        "    for f in mini_batch:\n",
        "        print('****working on mini_batch**********')\n",
        "        print(f)\n",
        "        #open text file in read mode\n",
        "        text_file = open(f, \"r\")\n",
        "        data = text_file.read()\n",
        "        text_file.close()\n",
        "        result = model.predict([data])\n",
        "        print(data)\n",
        "        resultList.append(\"{}: {}\".format(os.path.basename(f), result[0]))\n",
        "    return resultList"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing /mnt/batch/tasks/shared/LS_root/mounts/clusters/devbox/code/Users/babal/EmailClass/email_parallelRun_classificationbatch_pipeline/batch-inferencing/batch_inferencing_data.py\n"
        }
      ],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "You're going to use a pipeline to run the batch prediction script, generate predictions from the input data, and save the results as a text file in the output folder. To do this, you can use a **ParallelRunStep**, which enables the batch data to be processed in parallel and the results collated in a single output file named *parallel_run_step.txt*."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
        "from azureml.data import OutputFileDatasetConfig\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "\n",
        "output_dir = OutputFileDatasetConfig(name='inferences')\n",
        "\n",
        "parallel_run_config = ParallelRunConfig(\n",
        "    source_directory=script_folder,\n",
        "    entry_script=\"batch_inferencing_data.py\",\n",
        "    mini_batch_size=\"50\",\n",
        "    error_threshold=10,\n",
        "    output_action=\"append_row\",\n",
        "    environment=batch_env,\n",
        "    compute_target=compute_target,\n",
        "    node_count=2)\n",
        "\n",
        "parallelrun_step = ParallelRunStep(\n",
        "    name='batch-score-diabetes',\n",
        "    parallel_run_config=parallel_run_config,\n",
        "    inputs=[batch_data_set.as_named_input('email_batch')],\n",
        "    output=output_dir,\n",
        "    arguments=[],\n",
        "    allow_reuse=True\n",
        ")\n",
        "\n",
        "print('Steps defined')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Steps defined\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1644416912425
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "\n",
        "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
        "pipeline_run = Experiment(ws, '02-email-classifcation-batch').submit(pipeline)\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step batch-score-diabetes [8fc2b277][bee8c409-9ffd-4b24-a463-aad5e89d8c21], (This step will run and generate new outputs)\nSubmitted PipelineRun 69d940b3-cf03-411e-863f-b2393ee171c2\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/69d940b3-cf03-411e-863f-b2393ee171c2?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/mlopsdev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\nPipelineRunId: 69d940b3-cf03-411e-863f-b2393ee171c2\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/69d940b3-cf03-411e-863f-b2393ee171c2?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/mlopsdev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': '69d940b3-cf03-411e-863f-b2393ee171c2', 'status': 'Completed', 'startTimeUtc': '2022-02-09T14:28:46.525152Z', 'endTimeUtc': '2022-02-09T14:45:34.842054Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.69d940b3-cf03-411e-863f-b2393ee171c2/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=6yopmDGnvS1tB%2BGSzUE9zkHnBTIBvCF6ONsh3t2JX58%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T14%3A35%3A05Z&ske=2022-02-10T22%3A45%3A05Z&sks=b&skv=2019-07-07&st=2022-02-09T14%3A36%3A19Z&se=2022-02-09T22%3A46%3A19Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.69d940b3-cf03-411e-863f-b2393ee171c2/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=iqTv9BUvYki56TgbWsm3CfLq4zhbC%2BI48J2ysZl%2Bvl8%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T14%3A35%3A05Z&ske=2022-02-10T22%3A45%3A05Z&sks=b&skv=2019-07-07&st=2022-02-09T14%3A36%3A19Z&se=2022-02-09T22%3A46%3A19Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.69d940b3-cf03-411e-863f-b2393ee171c2/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=k%2BOuibgozW634NQfOdgaoko7E%2FMG5pYLFvstqUslXkU%3D&skoid=79188af8-05f3-4945-aaf5-b6abcecc3006&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-02-09T14%3A35%3A05Z&ske=2022-02-10T22%3A45%3A05Z&sks=b&skv=2019-07-07&st=2022-02-09T14%3A36%3A19Z&se=2022-02-09T22%3A46%3A19Z&sp=r'}, 'submittedBy': 'Balamurugan Balakreshnan'}\n\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\nThis usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\nPlease check for package conflicts in your python environment\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1644417978271
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve results"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# Remove the local results folder if left over from a previous run\n",
        "try:\n",
        "    shutil.rmtree('diabetes-results', ignore_errors=True)\n",
        "except:\n",
        "    print('keep going dude')\n",
        "\n",
        "# Get the run for the first step and download its output\n",
        "prediction_run = next(pipeline_run.get_children())\n",
        "prediction_output = prediction_run.get_output_data('inferences')\n",
        "prediction_output.download(local_path='diabetes-results')\n",
        "\n",
        "# Traverse the folder hierarchy and find the results file\n",
        "for root, dirs, files in os.walk('diabetes-results'):\n",
        "    for file in files:\n",
        "        if file.endswith('parallel_run_step.txt'):\n",
        "            result_file = os.path.join(root,file)\n",
        "\n",
        "# cleanup output format\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
        "df.columns = [\"File\", \"Prediction\"]\n",
        "\n",
        "# Display the first 20 results\n",
        "df.head(20)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Run' object has no attribute 'get_output_data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-429ea7bdf33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Get the run for the first step and download its output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprediction_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprediction_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inferences'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprediction_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'diabetes-results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Run' object has no attribute 'get_output_data'"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline_id = pipeline.Id\n",
        "# experiment_name = 'silly_scheduled_email'\n",
        "# recurrence = ScheduleRecurrence(frequency=\"Minute\", interval=5)\n",
        "# recurring_schedule = Schedule.create(ws, name=\"MyRecurringSchedule\", \n",
        "#                             description=\"Based on time\",\n",
        "#                             pipeline_id=pipeline_id, \n",
        "#                             experiment_name=experiment_name, \n",
        "#                             recurrence=recurrence)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python3-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}